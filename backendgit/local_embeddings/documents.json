[
    "LLM Already Serve Database Interface ? BIg Bench Large-Scale Database Grounded Text-to-SQLs Jinyang Li1 , \u2663 \u2021 , Binyuan Hui2 , \u2663 , Ge Qu1 , \u2663 , Jiaxi Yang2 , Binhua Li2 , Bowen Li6 , Bailin Wang5 , Bowen Qin2 , Ruiying Geng2 , Nan Huo1 , Xuanhe Zhou3 , Chenhao Ma6 , Guoliang Li3 , Kevin C.C . Chang7 , Fei Huang2 , Reynold Cheng1 , Yongbin Li2 1The University Hong Kong2DAMO Academy , Alibaba Group 3Tsinghua University4Shanghai AI Laboratory5MIT CSAIL 6The Chinese University Hong Kong , Shenzhen 7University Illinois Urbana-Champaign { jl0725 , quge } @ connect.hku.hk , ckcheng @ cs.hku.hk binyuan.hby @ alibaba-inc.com Abstract Text-to-SQL parsing , aims converting natural language questions executable SQLs , gained increasing attention recent years . particular , GPT-4 Claude-2 shown impressive results task . However , prevalent benchmarks , i.e. , Spider , WikiSQL , focus database schema rows database values leaving gap academic study real-world applications . mitigate gap , present",
    "results task . However , prevalent benchmarks , i.e. , Spider , WikiSQL , focus database schema rows database values leaving gap academic study real-world applications . mitigate gap , present BIRD , aBIg bench laRge-scale Database grounded text-to-SQL tasks , containing 12,751 text-to- SQL pairs 95databases total size 33.4 GB , spanning 37professional domains . emphasis database values highlights new challenges dirty noisy database values , external knowledge grounding NL questions database values , SQL efficiency , particularly context massive databases . solve problems , text-to-SQL models must feature database value comprehension addition semantic parsing . experimental results demonstrate significance database values generating accurate text-to-SQLs big databases . Furthermore , even effective text-to-SQL models , i.e . GPT-4 , achieve 54.89 % execution accuracy , still far human result 92.96 % , proving challenges still stand . also provide efficiency analysis offer insights",
    "effective text-to-SQL models , i.e . GPT-4 , achieve 54.89 % execution accuracy , still far human result 92.96 % , proving challenges still stand . also provide efficiency analysis offer insights generating text-to-efficient-SQLs beneficial industries . believe BIRDwill contribute advancing real-world applications text-to-SQL research . leaderboard source code available : https : //bird-bench.github.io/ . 1 Introduction Text-to-SQL parsing [ 55,50,51,3,52,37 ] , focuses converting natural language questions SQL queries , attracted significant research interests academia industry . attention stems potential empower non-expert data analysts automatically extracting desired information ubiquitous relational databases using natural language . Recent advances neural models , including based large language models ( LLMs ) , led impressive performance existing benchmarks SPIDER [ 53 ] WikiSQL [ 58 ] . instance , execution accuracy top-performing model SPIDER leaderboard increased 53.5 %",
    "large language models ( LLMs ) , led impressive performance existing benchmarks SPIDER [ 53 ] WikiSQL [ 58 ] . instance , execution accuracy top-performing model SPIDER leaderboard increased 53.5 % \u2663Equal contribution . \u2021Work done intern Alibaba DAMO Academy . 37th Conference Neural Information Processing Systems ( NeurIPS 2023 ) Track Datasets Benchmarks.External Knowledge ReasoningLarge Realistic Database ValuesSQL Execution Efficiency winning rate Boston Celtics 2000 ? SELECT COUNT ( ) / ( ( COUNT ( ) + COUNT ( lose ) ) teams team_name = \u2018 Boston Celtics \u2019 year = 2000 ; External Knowledge : winning rate = # / ( # + # lose ) average salaryof worst performing managers ? SELECTAVG ( CAST ( REPLACE ( SUBSTR ( T1.salary , 4 ) , ' , ' , `` ) ASREAL ) ) last_nameMilgrom\u2026 \u2026em_id0000\u2026 \u2026EmployeesUS $ 57,500.00first_namesalary22226543AdamsWoodMilgromSandyEmily\u2026 \u2026US $ 19,500.00US $ 69,000.00\u2026 \u2026Reasoned Database : employee AST1 JOINposition AST2 ONT1.positionID = T2.positionID",
    "\u2026EmployeesUS $ 57,500.00first_namesalary22226543AdamsWoodMilgromSandyEmily\u2026 \u2026US $ 19,500.00US $ 69,000.00\u2026 \u2026Reasoned Database : employee AST1 JOINposition AST2 ONT1.positionID = T2.positionID WHERET1.performance = 'Poor ' ANDT2.positiontitle = 'Manager ' Among coaches served 2 NBA teams , coach \u2018 period coaching , team least numbers games lost post-season games ? SELECT coachIDFROM coachesWHERE lgID='NBA \u2019 post_wins ! =0SQL1 : normal semantic parser post_losses ! =0 coachIDIN ( SELECT coachIDFROM coaches lgID='NBA \u2019 GROUP coachID COUNT ( tmID ) > =2 ) ORDER post_losses ASC LIMIT 1 ; Run time : 22.4s average salaryof worst performing managers ? SELECTAVG ( CAST ( REPLACE ( SUBSTR ( T1.salary , 4 ) , ' , ' , `` ) ASREAL ) ) last_nameMilgrom\u2026 \u2026em_id0000\u2026 \u2026EmployeesUS $ 57,500.00first_namesalary22226543AdamsWoodSantaSandyEmily\u2026 \u2026US $ 19,500.00US $ 69,000.00\u2026 \u2026Reasoned Database : employee AST1 JOINposition AST2 ONT1.positionID = T2.positionID WHERET1.performance = 'Poor '",
    "\u2026US $ 19,500.00US $ 69,000.00\u2026 \u2026Reasoned Database : employee AST1 JOINposition AST2 ONT1.positionID = T2.positionID WHERET1.performance = 'Poor ' ANDT2.positiontitle = 'Manager'SQL2 : efficient semantic parserSELECT coachIDFROM coachesWHERE lgID= \u2018 NBA \u2019 post_wins ! =0 post_losses ! =0 EXISTS ( SELECT 1 coaches AScoaches1 ( coaches1.lgID= \u2018 NBA \u2019 ) ( coaches.coachID=coaches1.coachID ) GROUP coaches1.coachID count ( coaches1.tmID ) > = 2ORDER NULL ) ORDER coaches.post_losses ASC LIMIT 1 Run time : 4.0sHow many accounts eligible loans New York City ? condition loans type account \u201c OWNER \u201d .SELECT COUNT ( * ) account account.type = \u2018 OWNER \u2019 city = \u2018 NY \u2019 ; External Knowledge : ( ) . ( b ) . ( c ) .How many accounts eligible loans New York City ? condition loans type account \u201c OWNER \u201d .SELECT COUNT ( * ) account account.type = \u2018 OWNER \u2019 disp_id = \u2018 NY \u2019 ; External Knowledge : List account id chooses weekly issue issuance statement ? \u2018 POPLATEK TYDNE \u2019 stands weekly issuance.SELECT",
    ".SELECT COUNT ( * ) account account.type = \u2018 OWNER \u2019 disp_id = \u2018 NY \u2019 ; External Knowledge : List account id chooses weekly issue issuance statement ? \u2018 POPLATEK TYDNE \u2019 stands weekly issuance.SELECT account_id account account.frequency= \u2018 POPLATEK TYDNE \u2018 ; External Knowledge : many accounts eligible loans New York City ? condition loans type account \u201c OWNER \u201d .SELECT COUNT ( * ) account account.type = \u2018 OWNER \u2019 disp_id = \u2018 NY \u2019 ; External Knowledge : List account id chooses weekly issue issuance statement ? \u2018 POPLATEK TYDNE \u2019 stands weekly issuance.SELECT account_id account account.frequency= \u2018 POPLATEK TYDNE \u2018 ; External Knowledge : average salary worst performing managers ? Figure 1 : Examples challenges BIRDbenchmark . 1 ) databases contain values noisy data types [ 14,23,19,31 ] . left example , average salary could fetched processing data type string ( TEXT SQLite ) float ( REAL SQLite ) deleting special tokens , '' US $ '' '' , '' . 2 ) external knowledge reasoning required .",
    "example , average salary could fetched processing data type string ( TEXT SQLite ) float ( REAL SQLite ) deleting special tokens , '' US $ '' '' , '' . 2 ) external knowledge reasoning required . middle example , models must handle `` OWNER '' accounts eligible loans . 3 ) query execution efficiency needs considered . right example , adoption efficient SQL queries leads significant gains speed , great value industries . [ 59 ] 85.3 % [ 35 ] past three years . latest SOTA parser [ 35 ] inSPIDER benefits powerful understanding coding capabilities large language model ( LLM ) , excellent performance leads us ask question : LLM already serve database interface ? answer , previous benchmarks focus database schema rows database values leaving gap academic study real world . shown Figure 1 , first , discovered current state-of-the-art models still struggle generalize realistic situations characterized large database sizes noisy values . Second , growth database sizes often results much",
    ", first , discovered current state-of-the-art models still struggle generalize realistic situations characterized large database sizes noisy values . Second , growth database sizes often results much context compression , making challenging reveal entire context [ 1 ] . Thus requires external knowledge reasoning comprehensive understanding . Third , existing benchmarks account SQL execution efficiency , holds significant practical importance real-life applications , notably case large databases . Motivated observations , aim develop new text- to-SQL benchmark better represents real-life scenarios narrows gap experimental practical settings . work , propose BIRD , aBIg Bench La Rge-Scale Database Grounded Text-to-SQLs real-world applications . BIRDcontains complex 12,751 examples querying information 95big databases total size 33.4 GB spanning 37professional domains . training development , collected modified 80 open-source relational databases real analysis platforms ( Kaggle ,",
    "information 95big databases total size 33.4 GB spanning 37professional domains . training development , collected modified 80 open-source relational databases real analysis platforms ( Kaggle , Relation.vit ) . avoid data leakage , curated 15 additional relational databases hidden test set . Given databases , rely crowdsourcing collect natural language questions corresponding SQLs . Additionally , propose new evaluation metric Valid Efficiency Score ( VES ) evaluate efficiency generated SQLs . best knowledge , BIRDis first text-to-SQL benchmark incorporate efficiency , promoting efficient query methods within context massive noisy database values . evaluate performance state-of-the-art text-to-SQL parsers using two popular methodologies : fine-tuning ( FT ) T5 [ 38 ] , in-context learning ( ICL ) advanced large language models ( LLMs ) ChatGPT [ 33 ] ( gpt-3.5-turbo ) , Claude-2 [ 2 ] ( claude-2.0 ) , GPT-4 [ 32 ] ( gpt-4-32k ) . experimental results demonstrate current models",
    "( ICL ) advanced large language models ( LLMs ) ChatGPT [ 33 ] ( gpt-3.5-turbo ) , Claude-2 [ 2 ] ( claude-2.0 ) , GPT-4 [ 32 ] ( gpt-4-32k ) . experimental results demonstrate current models struggle generalize well BIRD . Specifically , even GPT-4 achieves 54.89 % execution accuracy . comparison , performance still lags far behind human performance 92.96 % , proving challenges still stand . Moreover , perform comprehensive analysis provide insight direction . encourage research NLP DB communities jointly address realistic settings presented benchmark . 2 Task Formulation & Annotations Text-to-SQL refers process converting natural language question Qinto SQL query capable retrieving relevant data database . database represented D=\u27e8C , \u27e9 , 2How many bioassay signatures \u2026 \u2026What percentage male \u2026 \u2026What tag album \u2026 \u2026\u2026 \u2026\u2026 \u2026 SELECT COUNT ( T1.signature_id ) \u2026 \u2026SELECT CAST ( SUM ( CASE gender \u2026 \u2026\u2026 \u2026\u2026 \u2026SELECT T2.tag torrents \u2026 \u2026expertsAnnotationQuestion Crowd SQL Crowd 43 4 Annotation",
    "male \u2026 \u2026What tag album \u2026 \u2026\u2026 \u2026\u2026 \u2026 SELECT COUNT ( T1.signature_id ) \u2026 \u2026SELECT CAST ( SUM ( CASE gender \u2026 \u2026\u2026 \u2026\u2026 \u2026SELECT T2.tag torrents \u2026 \u2026expertsAnnotationQuestion Crowd SQL Crowd 43 4 Annotation Annotation 1 SupervisionSupervision Training & Test23 8 / 109 / 10enrollenrollOriginalColumnNameColumnNameDataTypeValueDescriptionColumnDescriptionaccount_iddistrict_idfrequency dateaccountiddistrictidfrequency dateUniqueididentifyingtheaccountLocationofbranchFreqofissuanceofstatements AccountopeningdateIntegerIntegerText DatetimePOPLATEKMESICNE : \u2026POPLATEKTYDNE : \u2026POPLATEKPOOBRATU : \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026What percentage male \u2026 \u2026SELECT CAST ( SUM ( CASE gender \u2026 \u2026SELECT CAST ( SUM ( CASE gender \u2026 \u2026 SELECT CAST ( SUM ( CASE gender \u2026 \u2026SELECT CAST ( SUM ( CASE gender \u2026 \u2026 Question : SQL1 : SQL2 : SQL1 : SQL2 : MATCHCheckUntil CollectRESULT 1RESULT 2RESULT 1RESULT 2MISMATCH ( ) Annotation Workflow ( b ) Double-blind Annotation ( c ) Database DescriptionFigure 2 : Overview BIRDAnnotation Workflow ( )",
    "SQL2 : MATCHCheckUntil CollectRESULT 1RESULT 2RESULT 1RESULT 2MISMATCH ( ) Annotation Workflow ( b ) Double-blind Annotation ( c ) Database DescriptionFigure 2 : Overview BIRDAnnotation Workflow ( ) . figure depicts four-step procedure . ( 1 ) workflow begins specialists assembling producing databases description files . ( 2 ) Experts teach evaluate crowdsourcing people , keeping pass evaluation . ( 3 ) Question annotators create corpus questions using databases corresponding description files . ( 4 ) SQL annotators produce SQL files , equipped databases , descriptions , questions . ( b ) ( c ) also depict Double-blind annotation procedure example database descriptions . CandTare columns tables respectively . dealing complex database values , BIRD , crucial incorporate external knowledge evidence , denoted K , improve models \u2019 understanding database values . Finally , text-to-SQL could formulated : Y=f ( Q , , K |\u03b8 ) , ( 1 ) function f ( \u00b7 |\u03b8 ) represent model neural network parameter",
    ", denoted K , improve models \u2019 understanding database values . Finally , text-to-SQL could formulated : Y=f ( Q , , K |\u03b8 ) , ( 1 ) function f ( \u00b7 |\u03b8 ) represent model neural network parameter \u03b8 . 3 Dataset Construction 3.1 Annotation Entrance deliver high-quality benchmark , administer thorough exams applicants hire pass rigorous tests . information available Appendix B.2 . 3.2 Database Source difficult collect databases complex schemas sufficient value due privacy protection . Earlier works [ 45,53 ] choose self-design database schemas value production . Nonetheless , value distribution schemas may differ real-world scenarios way . work , obtain process databases three different sources enrich real-world attributes . 32 % databases sourced Kaggle * , platform renowned holding data science competitions difficult , noisy values schemas . Another 48 % come CTU Prague Relational Learning Repository\u2020 , open platform machine learning research multi-relational data . remaining 20 % built",
    "competitions difficult , noisy values schemas . Another 48 % come CTU Prague Relational Learning Repository\u2020 , open platform machine learning research multi-relational data . remaining 20 % built acquiring open tables , synthesizing standardizing schemas , generating database constraints . databases contain real large value distributions easily accessible appropriate licenses . Finally , present 95 databases consisting 69 , 11 , 15 databases training , development , testing respectively . databases cover 37 professional domains , including blockchain , sports , health care , politics , etc . anticipate significant resource researchers explore domain generalization semantic parsing tasks large database values . * https : //www.kaggle.com/ \u2020https : //relational.fit.cvut.cz/ 33.3 Question Annotation Database Description File . Database Description File crucial resource designed aid annotators comprehending database values , thereby allowing ask insightful questions . offers two primary",
    "Database Description File . Database Description File crucial resource designed aid annotators comprehending database values , thereby allowing ask insightful questions . offers two primary pieces information regarding database . ( 1 ) Full schema names : database table column names frequently abbreviated , difficult understand . ( 2 ) Value description : aspect particularly useful phrases tokens question directly match values database . External Knowledge Evidence . study professional data analysis , find external knowledge evidence required map natural language instructions counterpart database values . Therefore , collect classify evidence four categories : ( 1 ) Numeric Reasoning Knowledge : category refers mathematical computation required certain SQL operations . benchmark , present 8 basic math operations , including 4 complex operations [ 7 ] : MINUS , ADDITION , DIVISION , MULTIPLY .BIRDalso contains compositional operations basic ones , percentages , formulas , etc . ( 2 )",
    "8 basic math operations , including 4 complex operations [ 7 ] : MINUS , ADDITION , DIVISION , MULTIPLY .BIRDalso contains compositional operations basic ones , percentages , formulas , etc . ( 2 ) Domain Knowledge : category consists domain-specific knowledge utilized generate SQL operations [ 10,57 ] . instance , business analyst banking business requires knowledge financial indicators return investment net income order generate effective SQL queries . ( 3 ) Synonym Knowledge : category includes words expressions similar meanings regardless phrased differently [ 11 ] . ( 4 ) Value Illustration : category refers detailed descriptions database values , including value types , value categories , mapping combinations columns values correspond entities , example : `` center '' represented `` pos = C '' database professional_basketball . 3.4 SQL Annotation Double-Blind Annotation . shown Figure 2 ( b ) , employ double-blind approach [ 42 ] SQL annotation . approach involves two",
    "`` pos = C '' database professional_basketball . 3.4 SQL Annotation Double-Blind Annotation . shown Figure 2 ( b ) , employ double-blind approach [ 42 ] SQL annotation . approach involves two independent SQL annotators generate SQLs question without discussion . annotated SQLs executed databases , yielding identical results gathered . Otherwise , SQLs checked experts consensus reached . Double-blind procedures dramatically reduce SQL annotation error rate , small probability two skillful annotators generate incorrect results databases large values . semantic-equivalent efficient SQL selected experts question picked ground truth SQL BIRD , external knowledge evidence sentences recorded SQL utilized . Examination . Experts evaluate text-to-SQL pair ensure highest quality data . evaluation process includes two dimensions : SQL validness , text-knowledge-SQL alignment . Firstly , SQL validness confirmed SQL executable return valid result database . `` valid result '' refers set results ``",
    "includes two dimensions : SQL validness , text-knowledge-SQL alignment . Firstly , SQL validness confirmed SQL executable return valid result database . `` valid result '' refers set results `` NULL '' . executed result set `` NULL '' , experts make slight changes conditions questions associated SQLs provide valid result set . Secondly , text-knowledge-SQL alignment involved ensure SQL generated given texts knowledge evidence . evidence insufficient generate SQL contains errors , experts charge correcting . 4 Data Statistics Overall Statistics Table 1 presents overview comparison BIRDand cross-domain text-to-SQL benchmarks . statistics demonstrate , BIRDis large-scale cross-domain bench- mark , covering complex SQL functions , knowledge reasoning , efficiency evaluation . Question Statistics Database values bring challenges text-to-SQLs . order underscore , classify questions two macro-categories : Fundamental Type Reasoning Type , contains 4-5 micro-categories detail . Fundamental",
    "Database values bring challenges text-to-SQLs . order underscore , classify questions two macro-categories : Fundamental Type Reasoning Type , contains 4-5 micro-categories detail . Fundamental Type questions refers answered without database value comprehension . contains Match-based ( 83.9 % ) , Ranking ( 20.3 % ) , Comparison ( 16.7 % ) , Counting ( 30.4 % ) , Aggregation ( 15.7 % ) . 4Table 1 : overview comparison BIRDand cross-domain text-to-SQL benchmarks . SQL , Function pertains SQL functions ( Appendix B.11 ) . Knowledge refers whether dataset necessitates external knowledge reasoning model . Efficiency refers whether dataset takes consideration execution efficiency . Dataset # Example # DB # Table/DB # Row/DB Function Knowledge Efficiency WikiSQL [ 58 ] 80,654 26,521 1 17 SPIDER [ 53 ] 10,181 200 5.1 2K KaggleDBQA [ 24 ] 272 8 2.3 280K BIRD 12,751 95 7.3 549K",
    ". Dataset # Example # DB # Table/DB # Row/DB Function Knowledge Efficiency WikiSQL [ 58 ] 80,654 26,521 1 17 SPIDER [ 53 ] 10,181 200 5.1 2K KaggleDBQA [ 24 ] 272 8 2.3 280K BIRD 12,751 95 7.3 549K retailsportmoviesoftwareuniversitygeographycartoonITfoodtransportationhealthcaregamesbooksfinancialrestaurantcriminallawacademicmedicaleconomieschemistryvisionmusictv_seriesbankingairportpublicationseducationweatherhuman resourcesblockchainbiologyworks_cyclesretail_worldretailsregional_salescar_retailssuperstoresalesretail_complainssoccer_2016hockeyformula_1olympicsprofessional_basketballeuropean_football_2ice_hockey_drafteuropean_football_1movie 3movie_platformmovies_4movielensmovietalkingdatacodebase_communitycodebase_commentssocial_mediasoftware_companystudent_clubuniversitycs_semestercollege_completioncomputer_studentmondial_geoaddressworldsimpson_episodessuperherodisneypublic_review_platformapp_storefood_inspection_2beer_factoryfood_inspectioncookbook",
    "craftbeerbike_share_1shippingtrainscarssyntheadonormental_health_surveyvideo_gamescard_gamesbooksshakespearestudent_loandebit_card_specializingrestaurantmenuchicago_crime shootinglegislatorauthorsthrombosis_predictionworld_development_indicatorstoxicologyimage_and_languagemusic_platform_2music_trackerlaw_episodefinancialairlinebook_publishing_companyciteseercalifornia_schoolssales_in_weatherhuman_resourcescoinmarketcapgenes 050010001500200025003000350040004500sizeDomain Distribution Loading [ MathJax ] /extensions/MathMenu.jstraindev testtotalTEXTINTEGERREALDATE_RELATED50.635.08.75.640.247.1 9.43.351.337.33.38.049.436.88.05.7Percentage ( % ) Percentage ( % ) ( ) ) Database domain distribution w/ sizeb ) Database value type distribution Figure 3 : comprehensive database distribution BIRD . ) shows domain size distribution database . b ) shows data type distribution databases . Reasoning Type entails questions demand external knowledge grounding values , exclusive BIRD . specific ,",
    ". ) shows domain size distribution database . b ) shows data type distribution databases . Reasoning Type entails questions demand external knowledge grounding values , exclusive BIRD . specific , questions Domain Knowledge ( 23.6 % ) , Numeric Computing ( 24.5 % ) , Synonym ( 7.2 % ) , Value Illustration ( 70.1 % ) , in- volved B IRD . ample examples Appendix B.3 . addition , observe 70.1 % questions need value illustrations . indicates real-world questions text-to-SQL applications demand thorough understanding database values , consistent motivation creating B IRDbenchmark . Database Statistics InBIRD , investigate distribution database domains , database size , value types . Figure 3 ( ) presents detailed distribution domains counterpart databases sunburst diagram training development sets . area semi-circle corresponds number text-to-SQL pairs database . Figure 3 ( ) also shows size distributions databases . darker color means larger size databases , vice versa . example ,",
    "sets . area semi-circle corresponds number text-to-SQL pairs database . Figure 3 ( ) also shows size distributions databases . darker color means larger size databases , vice versa . example , database Donor largest database 4.5 GB dataset . Furthermore , observe Figure 3 ( b ) considerable proportion BIRD \u2019 data comprises date-related values . Considering real-world applications often rely time-sensitive data [ 25 ] , prevalence questions highlights practical purposes . SQL Statistics provide complexity diversity SQLs BIRD . illustrated Figure 4 , present comprehensive distribution analysis SQLs across four dimensions . No.Toks / SQL andNo.JOINs / SQL demonstrate intricacy SQLs BIRD.No.of Keywords andNo.n-grams / SQL ( n=3 ) serve support diverse patterns SQLs since decouple question SQL annotation procedures make situation realistic [ 6 ] . 5 Evaluation Metrics contexts practical data analysis , text-to-SQL models prioritized delivering expected results accurately efficiently . Thus",
    "annotation procedures make situation realistic [ 6 ] . 5 Evaluation Metrics contexts practical data analysis , text-to-SQL models prioritized delivering expected results accurately efficiently . Thus provide two metrics BIRD , execution accuracy ( EX ) 5No . Toks / SQLNo . KeywordsNo . n-grams / SQL ( n=3 ) . JOINs / SQLWikiSQLSpiderKaggleDBQABirdFigure 4 : comparative statistical analysis SQL queries BIRDdataset cross- domain text-to-SQL benchmarks . valid efficiency score ( VES ) evaluate text-to-SQL parsers confronted large real-world database values . Execution Accuracy ( EX ) EX defined proportion examples evaluation set executed results predicted ground-truth SQLs identical , relative overall number SQLs [ 37 ] . Considering result set Vnexecuted nthground-truth SQL Yn , result set \u02c6Vnexecuted predicted SQL \u02c6Yn , EX computed : EX =\u03a3N n=1 1 ( Vn , \u02c6Vn ) N , ( 2 ) 1 ( \u00b7 ) indicator function , represented : 1 ( V , \u02c6V ) = ( 1 , V =\u02c6V 0 , V\u0338=\u02c6V ( 3 ) Valid Efficiency Score ( VES )",
    "\u02c6Vnexecuted predicted SQL \u02c6Yn , EX computed : EX =\u03a3N n=1 1 ( Vn , \u02c6Vn ) N , ( 2 ) 1 ( \u00b7 ) indicator function , represented : 1 ( V , \u02c6V ) = ( 1 , V =\u02c6V 0 , V\u0338=\u02c6V ( 3 ) Valid Efficiency Score ( VES ) VES designed measure efficiency valid SQLs generated models . worth noting term `` valid SQLs '' refers predicted SQL queries whose result sets align ground-truth SQLs . SQL queries fail fetch correct values declared invalid since totally useless fulfill user requests , regardless efficiency . case , VES metric considers efficiency accuracy execution results , providing comprehensive evaluation model \u2019 performance . Formally , VES expressed : VES =\u03a3N n=1 1 ( Vn , \u02c6Vn ) \u00b7R ( Yn , \u02c6Yn ) N , R ( Yn , \u02c6Yn ) =s E ( Yn ) E ( \u02c6Yn ) ( 4 ) whereR ( \u00b7 ) denotes relative execution efficiency predicted SQL comparison ground-truth SQL , allowing machine status-related uncertainty . E ( \u00b7 ) function measure absolute execution efficiency SQL given environment\u2021 . Furthermore , incorporate square root",
    "SQL comparison ground-truth SQL , allowing machine status-related uncertainty . E ( \u00b7 ) function measure absolute execution efficiency SQL given environment\u2021 . Furthermore , incorporate square root function minimize random instances abnormally faster slower ground-truth SQLs . , efficiency refer running time , throughput , memory cost , merged metrics . BIRD , consider running time mainly time . Appendix B.8 provides detailed description VES . 6 Experiments 6.1 Baseline Models present performance two types baseline models BIRD . first type model based fine-tuning ( FT ) techniques , outputs SQL tuning parameters language models learn annotated train set . hand , second type model based \u2021InBIRDevaluation , run 100 times SQL CPU evaluate average results dropping outliers . 6Figure 5 : bar chart provides clear visualization performance advanced models BIRD . Table 2 : Execution Accuracy ( EX ) advanced text-to-SQL models BIRD . human performance also provided . ModelsDevelopment Data",
    "chart provides clear visualization performance advanced models BIRD . Table 2 : Execution Accuracy ( EX ) advanced text-to-SQL models BIRD . human performance also provided . ModelsDevelopment Data Testing Data w/o knowledge w/ knowledge w/o knowledge w/ knowledge FT-based T5-Base 6.32 11.54 ( +5.22 ) 7.06 12.89 ( +5.83 ) T5-Large 9.71 19.75 ( +10.04 ) 10.38 20.94 ( +10.56 ) T5-3B 10.37 23.34 ( +12.97 ) 11.17 24.05 ( +12.88 ) ICL-based Palm-2 18.77 27.38 ( +8.61 ) 24.71 33.04 ( +8.33 ) Codex 25.42 34.35 ( +8.93 ) 24.86 36.47 ( +11.61 ) ChatGPT 24.05 37.22 ( +13.17 ) 26.77 39.30 ( +12.53 ) ChatGPT + COT 25.88 36.64 ( +10.76 ) 28.95 40.08 ( +11.24 ) Claude-2 28.29 42.70 ( +14.41 ) 34.60 49.02 ( +14.42 ) GPT-4 30.90 46.35 ( +15.45 ) 34.88 54.89 ( +20.01 ) GPT-4 + DIN-SQL - 50.72 - 55.90 Human Performance - - 72.37 92.96 ( +20.59 ) in-context learning ( ICL ) , generate results without additional training . FT models , select T5 family [ 38 ] main baseline models . ICL-based models ,",
    "Human Performance - - 72.37 92.96 ( +20.59 ) in-context learning ( ICL ) , generate results without additional training . FT models , select T5 family [ 38 ] main baseline models . ICL-based models , provide zero-shot results Codex ( code-davinci-002 ) , ChatGPT ( gpt-3.5-turbo ) , GPT-4 ( gpt-4-32k ) , Claude-2 ( claude-2.0 ) , Palm-2 ( text-bison-001 ) . Additionally , also implement state-of-the-art ( SOTA ) model SPIDER , DIN-SQL [ 35 ] , evaluate challenges proposed BIRDdataset . Table 2 , Table 3 Figure 5 present overall results advanced language models B IRD . 6.2 Execution Accuracy Analysis Table 2 Figure 5 presents stratified performances various models BIRD . GPT-4 surpasses baseline language models . Claude-2 closely follows , demonstrating outstanding abilities semantic parsing knowledge reasoning . , incorporation dedicated reasoning prompt [ 35 ] , enables DIN-SQL + GPT-4 achieve new state-of-the-art result BIRD . contains value sampling , few-shot demonstrations ,",
    "knowledge reasoning . , incorporation dedicated reasoning prompt [ 35 ] , enables DIN-SQL + GPT-4 achieve new state-of-the-art result BIRD . contains value sampling , few-shot demonstrations , self-correction . Despite considerable advancements Language Model Learning ( LLMs ) prompt intelligence , performance models lags obviously behind human capabilities . gap highlight complex nature BIRD , also presents opportunities uncovering capable models advanced reasoning prompt methods applicable real-world text-to-SQL scenarios . 7Table 3 : Valid Efficiency Score ( VES ) advanced text-to-SQL models BIRD . human performance also presented . ModelsDevelopment Data Testing Data w/o knowledge w/ knowledge w/o knowledge w/ knowledge FT-based T5-Base 7.78 12.90 ( +5.12 ) 8.97 14.71 ( +5.74 ) T5-Large 9.90 22.74 ( +12.84 ) 12.25 25.00 ( +12.75 ) T5-3B 13.62 25.57 ( +11.95 ) 15.17 27.80 ( +12.63 ) ICL-based Palm-2 20.82 28.64 ( +7.82 ) 31.32 38.41 ( +7.09 ) Codex 33.37 43.41 ( +10.04 ) 35.40",
    "9.90 22.74 ( +12.84 ) 12.25 25.00 ( +12.75 ) T5-3B 13.62 25.57 ( +11.95 ) 15.17 27.80 ( +12.63 ) ICL-based Palm-2 20.82 28.64 ( +7.82 ) 31.32 38.41 ( +7.09 ) Codex 33.37 43.41 ( +10.04 ) 35.40 41.60 ( +6.20 ) ChatGPT 27.97 43.81 ( +15.84 ) 36.68 51.40 ( +14.72 ) ChatGPT + COT 32.33 42.30 ( +9.97 ) 49.69 56.56 ( +6.87 ) Claude-2 32.75 45.28 ( +12.53 ) 39.32 55.77 ( +16.45 ) GPT-4 34.60 49.77 ( +15.17 ) 40.20 60.77 ( +20.57 ) GPT-4 + DIN-SQL - 58.79 - 59.44 Human Performance - - 70.36 90.27 ( +19.91 ) 6.3 Baseline Performance Spider DIN-SQLChatGPTCodexT5-3BT5-LargeT5-Base82.850.772.174.171.569.357.937.234.423.319.811.5SPIDERBIRD Figure 6 : EX results baseline models PIDER B IRDdev set.SPIDER [ 53 ] prevalent complex cross-domain text-to-SQL benchmark . mainly focuses evaluating schema-relevant seman- tic parsing capabilities . demonstrate in- creasing difficulty BIRDdataset due complex database schema values , visualize execution accuracy baseline models BIRDandSPIDER datasets . ensure",
    "seman- tic parsing capabilities . demonstrate in- creasing difficulty BIRDdataset due complex database schema values , visualize execution accuracy baseline models BIRDandSPIDER datasets . ensure fair evaluation , models furnished knowledge values , programming prompt implemented Language Models ( LMs ) across two datasets . Figure 6 shows concentration database values makes BIRDbecome challenging text-to-SQL benchmark . dis- parity performance model demon- strates need research develop- ment models capable handling complicated database schema values . 6.4 Efficiency Analysis According Table 3 , observe models higher EX possibly achieve higher VES . explained prerequisite text-to-SQL models must accurately predict results order attain higher VES , fulfills practical purpose . Two-Stage Optimization . Intuitively , goal text-to-efficient-SQL conversion de- composed two sub-stages . Following previous text-to-SQL tasks , first sub-stage , semantic parsing , concentrates accurately",
    "Optimization . Intuitively , goal text-to-efficient-SQL conversion de- composed two sub-stages . Following previous text-to-SQL tasks , first sub-stage , semantic parsing , concentrates accurately converting questions SQL queries . second sub-stage involves optimizing SQL queries , rewriting efficient maintaining results [ 61 ] . demonstrate efficacy approach , selected 10 random examples development set ChatGPT accurately predicted results . , specialists optimize queries based established query optimization rules [ 28,34,62 ] . observe two-stage optimization leads average time-saving 77.75 % keeping results . Chat w/ Database . BIRDintroduces novel mode `` Chat Database '' , enables models aware data types distributions generating global SQL queries interact databases . approach lays foundation development effective efficient SQL queries . observed experiment , time-saving percentage SQL queries 8match-basedrankingcomparison aggregationdomain KGmathsynonymvalue illustration",
    "lays foundation development effective efficient SQL queries . observed experiment , time-saving percentage SQL queries 8match-basedrankingcomparison aggregationdomain KGmathsynonymvalue illustration countingmatch-basedrankingcomparisoncountingaggregationdomain KGmathsynonymvalue illustrationrankingmatch-basedvalue illustrationsynonymmathdomain KGaggregationcountingcomparison2023/10/24 01:55Untitled visualization | Flourish https : //app.\ufb02ourish.studio/visualisation/15455665/edit1/1\uf00c\uf1fe\uf0ceCombinedSeparateChatGPTGPT-4Claude-2 000101010202020303030404040505050111222333444555666777888 \uf0da\uf0da\uf0da\uf0da\uf0da\uf0da\uf0da\uf0da\uf128\uf078\uf078\uf128 \uf128\uf078\uf078\u2584 \uf0da\uf015\uf0aa\uf019\uf1c5\uf055\uf1c9\uf005\uf078\uf078 match-basedrankingcomparisoncountingaggregationdomain KGmathsynonymvalue illustrationChatGPTGPT-4Claude-2OverallChatGPTGPT-4Claude-2Figure 7 : fine-grained categorical evaluation advanced large language models B IRD . reached 87.3 % configuring indexes within database . detailed efficiency analysis presented Appendix B.5 . 6.5 Knowledge Evidence Analysis implement baseline model two",
    "large language models B IRD . reached 87.3 % configuring indexes within database . detailed efficiency analysis presented Appendix B.5 . 6.5 Knowledge Evidence Analysis implement baseline model two scenarios . first provide ground truth external knowledge evidence sentence ( w/o knowledge ) sample . testing bed provide evidence ( w/ knowledge ) make text-to-SQL models knowledge grounding . discuss Section 3.3 , expert annotations external knowledge evidence sentences employed enhance model \u2019 comprehension database values . easily fed external knowledge evidence database values , models clear improvement across different difficulty levels shown Table 2 Table 4 . indicates external knowledge evidence BIRDis effective instructive models better understand database values . Also illustrates database values important text-to-SQL models facing real databases . Besides , ICL-based approaches better self-knowledge grounding capability pre-trained SQL knowledge FT smaller models less 5B",
    "database values important text-to-SQL models facing real databases . Besides , ICL-based approaches better self-knowledge grounding capability pre-trained SQL knowledge FT smaller models less 5B parameters . Equipped COT , ChatGPT perform better , since multi-step reasoning beneficial knowledge data low-resource . Despite , observe decline limited improvements performance ChatGPT + external knowledge evidence COT version . hypothesize internal multi-step knowledge reasoning LLMs compatible way external knowledge ( evidence ) situation . Therefore , development methods effectively combine strong multi-step self-reasoning capabilities LLMs external knowledge reasoning coherently presents promising future direction [ 29 ] . 6.6 Analysis Fine-grained Category Analysis . Figure 7 provides detailed comparison various dimensions sub-capabilities advanced LLMs BIRD . results indicate GPT-4 exhibits superior performance ChatGPT Claude-2 areas . Nevertheless , notable disparity performance",
    "detailed comparison various dimensions sub-capabilities advanced LLMs BIRD . results indicate GPT-4 exhibits superior performance ChatGPT Claude-2 areas . Nevertheless , notable disparity performance ranking numerical computing ( math ) among models . limitation may suggest inadequacy contemporary LLMs deep data science tasks tasks always incorporate mathematical computations rankings within context vague user queries . Conversely , models demonstrate relatively better performance domain knowledge , synonym detection , value illustration , attributed adequate linguistic training reasoning capabilities pretraining phases . Human Performance . order activate efforts text-to-SQL studies achieve application-level performance real-world scenarios , provide human performance BIRD . Table 2 , Table 3 shows \u2019 still huge gap even SOTA text-to-SQL models human performance . thorough introduction procedures Appendix B.9 . Error Analysis . ChatGPT currently prevalent cost-efficient LLM .",
    "2 , Table 3 shows \u2019 still huge gap even SOTA text-to-SQL models human performance . thorough introduction procedures Appendix B.9 . Error Analysis . ChatGPT currently prevalent cost-efficient LLM . Therefore , performance ChatGPT concentrated error analysis . detailed analysis Appendix B.6 . observe 500 randomly sampled error cases , providing in-depth assessment following 9categories . Wrong Schema Linking ( 41.6 % ) pertains scenario ChatGPT accurately comprehend structure database erroneously associates inappropriate columns tables . demonstrates task schema linking [ 43,57 ] , even intricate practical situations , continues significant obstacle models . Misunderstanding Database Content ( 40.8 % ) occurs ChatGPT either fails recall correct database structure ( e.g. , rtype \u2019 belong satscores table ) generates fake schema items ( e.g. , lap_records appearing formula_1 database many values predicted incorrectly ) especially database large . case , make ChatGPT really understand",
    "satscores table ) generates fake schema items ( e.g. , lap_records appearing formula_1 database many values predicted incorrectly ) especially database large . case , make ChatGPT really understand database structure values [ 27 ] still pain point topic LLMs . Misunderstanding Knowledge Evidence ( 17.6 % ) refers cases model accurately interpret human-annotated evidence . instance ChatGPT directly copies formula DIVIDE ( SUM ( spent ) , COUNT ( spent ) ) . finding demonstrates ChatGPT exhibits lack robustness response unfamiliar prompts knowledge , causing directly replicate formulas without considering SQL syntax [ 15 ] . also observe ChatGPT occasionally employs incorrect keywords ( e.g. , misusing MySQL Year ( ) function instead SQLite function STRFTIME ( ) ) exhibits decoding errors . 7 Related Work High-quality datasets crucial advancing various natural language processing tasks , including text-to-SQL . Early single-domain text-to-SQL datasets like GeoQuery [ 55 ] , ATIS [ 9 ] ,",
    "7 Related Work High-quality datasets crucial advancing various natural language processing tasks , including text-to-SQL . Early single-domain text-to-SQL datasets like GeoQuery [ 55 ] , ATIS [ 9 ] , Restaurant [ 20 ] targeted specific information retrieval tasks , recent datasets WikiSQL [ 58 ] andSPIDER [ 53 ] propose cross-domain dataset require domain generalization . However , cross-domain text-to-SQL datasets still emphasize database schema rather values , diverging real-world scenarios . KaggleDBQA [ 24 ] addressed constructing 272 text-to-SQL pairs eight databases Kaggle , datasets like EHRSQL [ 25 ] , SEDE [ 13 ] , MIMICSQL [ 46 ] collected diverse , large-value databases professional SQL queries . Despite advancements , datasets remain single-domain focused . Recent work explored knowledge-intensive text-to-SQL benchmarks [ 10,57 ] , aiding experts real-world analysis knowledge grounding . BIRD first large-scale benchmark incorporate real-world features , emphasizing",
    "explored knowledge-intensive text-to-SQL benchmarks [ 10,57 ] , aiding experts real-world analysis knowledge grounding . BIRD first large-scale benchmark incorporate real-world features , emphasizing database values . 8 Limitation Future work Despite high quality SQL annotation produced double-blind annotation , procedure resource-intensive . Future research could explore human-computer interaction ( HCI ) based approach , incorporating advanced AI systems GPT-4 taking parts annotation duties , maintain data quality reducing human effort . addition , SQLite chosen primary SQL codebase previous text-to-SQL benchmarks study since \u2019 friendly users . presents difficulties fetching Query Execution Plans ( QEP ) precise efficiency computation adapting different SQL syntaxes . Future work include PostgreSQL MySQL versions ofBIRDto resolve limitations provide robust research environment NLP DB experts . 9 Conclusion paper , introduce BIRD , large-scale cross-domain , text-to-SQL benchmark",
    "PostgreSQL MySQL versions ofBIRDto resolve limitations provide robust research environment NLP DB experts . 9 Conclusion paper , introduce BIRD , large-scale cross-domain , text-to-SQL benchmark particular focus large database values . BIRDmitigates gap text-to-SQL research real-world applications exploring three additional challenges : 1 ) handling large dirty database values , 2 ) external knowledge evidence , 3 ) optimizing SQL execution efficiency . experimental results demonstrate BIRDpresents daunting challenge compared existing benchmarks since even popular powerful LLM , ChatGPT , falls significantly short human performance . leaves plenty room improvement innovation text-to-SQL tasks . Moreover , thorough efficiency error analyses provide valuable insights directions future research , paving way development advanced practical text-to-SQL solutions real- world scenarios . 10Acknowledgement thank constructive comments anonymous reviewers . Reynold Cheng , Jinyang Li , Ge Qu Nan",
    ", paving way development advanced practical text-to-SQL solutions real- world scenarios . 10Acknowledgement thank constructive comments anonymous reviewers . Reynold Cheng , Jinyang Li , Ge Qu Nan Huo supported Hong Kong Jockey Club Charities Trust ( Project 260920140 ) University Hong Kong ( Project 104006830 ) . Chenhao supported NSFC Grant 62302421 , Basic Applied Basic Research Fund Guangdong Province Grant 2023A1515011280 , Shenzhen Science Technology Program ZDSYS20211021111415025 . Jinyang Li Ge Qu supported HKU Presidential PhD Scholar Programme . Ge Qu also funded Hong Kong PhD Fellowship Scheme . work supported Alibaba Group Alibaba Research Intern Program . References [ 1 ] Peter Alsberg . Space time savings large data base compression dynamic restructuring . Proceedings IEEE , 63:1114\u20131122 , 1975 . [ 2 ] Anthropic . Introducing Claude . 2023 . URL https : //www.anthropic.com/index/ introducing-claude . [ 3 ] Ruichu Cai , Boyan Xu , Zhenjie Zhang , Xiaoyan Yang , Zijian Li",
    "63:1114\u20131122 , 1975 . [ 2 ] Anthropic . Introducing Claude . 2023 . URL https : //www.anthropic.com/index/ introducing-claude . [ 3 ] Ruichu Cai , Boyan Xu , Zhenjie Zhang , Xiaoyan Yang , Zijian Li , Zhihao Liang . encoder-decoder framework translating natural language database queries . Proceedings Twenty-Seventh International Joint Conference Artificial Intelligence ( IJCAI-18 ) , page 3977\u20133983 , 2018 . [ 4 ] Zefeng Cai , Xiangyu Li , Binyuan Hui , Min Yang , Bowen Li , Binhua Li , Zheng Cao , Weijie Li , Fei Huang , Luo Si , Yongbin Li . STAR : SQL guided pre-training context-dependent text-to-SQL parsing . Findings Association Computational Linguistics : EMNLP 2022 , pages 1235\u20131247 , Abu Dhabi , United Arab Emirates , December 2022 . Association Computational Linguistics . [ 5 ] Ruisheng Cao , Lu Chen , Zhi Chen , Yanbin Zhao , Su Zhu , Kai Yu . LGESQL : Line graph enhanced text-to-SQL model mixed local non-local relations . Proceedings 59th Annual Meeting Association",
    "[ 5 ] Ruisheng Cao , Lu Chen , Zhi Chen , Yanbin Zhao , Su Zhu , Kai Yu . LGESQL : Line graph enhanced text-to-SQL model mixed local non-local relations . Proceedings 59th Annual Meeting Association Computational Linguistics 11th International Joint Conference Natural Language Processing ( Volume 1 : Long Papers ) , pages 2541\u20132555 , Online , August 2021 . Association Computational Linguistics . [ 6 ] Shuaichen Chang , Jun Wang , Mingwen Dong , Lin Pan , Henghui Zhu , Alexander Hanbo Li , Wuwei Lan , Sheng Zhang , Jiarong Jiang , Joseph Lilien , Steve Ash , William Yang Wang , Zhiguo Wang , Vittorio Castelli , Patrick Ng , Bing Xiang . Dr.spider : diagnostic evaluation benchmark towards text-to-SQL robustness . Eleventh International Conference Learning Representations , 2023 . [ 7 ] Zhiyu Chen , Wenhu Chen , Charese Smiley , Sameena Shah , Iana Borova , Dylan Langdon , Reema Moussa , Matt Beane , Ting-Hao Huang , Bryan Routledge , William Yang Wang . FinQA : dataset numerical",
    "] Zhiyu Chen , Wenhu Chen , Charese Smiley , Sameena Shah , Iana Borova , Dylan Langdon , Reema Moussa , Matt Beane , Ting-Hao Huang , Bryan Routledge , William Yang Wang . FinQA : dataset numerical reasoning financial data . Proceedings 2021 Conference Empirical Methods Natural Language Processing , pages 3697\u20133711 , Online Punta Cana , Dominican Republic , November 2021 . Association Computational Linguistics . [ 8 ] Aakanksha Chowdhery , Sharan Narang , Jacob Devlin , Maarten Bosma , Gaurav Mishra , Adam Roberts , Paul Barham , Hyung Chung , Charles Sutton , Sebastian Gehrmann , Parker Schuh , Kensen Shi , Sasha Tsvyashchenko , Joshua Maynez , Abhishek Rao , Parker Barnes , Yi Tay , Noam M. Shazeer , Vinodkumar Prabhakaran , Emily Reif , Nan Du , Benton C. Hutchinson , Reiner Pope , James Bradbury , Jacob Austin , Michael Isard , Guy Gur-Ari , Pengcheng Yin , Toju Duke , Anselm Levskaya , Sanjay Ghemawat , Sunipa Dev , Henryk Michalewski , Xavier Garc\u00eda , Vedant Misra , Kevin",
    ", James Bradbury , Jacob Austin , Michael Isard , Guy Gur-Ari , Pengcheng Yin , Toju Duke , Anselm Levskaya , Sanjay Ghemawat , Sunipa Dev , Henryk Michalewski , Xavier Garc\u00eda , Vedant Misra , Kevin Robinson , Liam Fedus , Denny Zhou , Daphne Ippolito , David Luan , Hyeontaek Lim , Barret Zoph , Alexander Spiridonov , Ryan Sepassi , David Dohan , Shivani Agrawal , Mark Omernick , Andrew M. Dai , Thanumalayan Sankaranarayana Pillai , Marie Pellat , Aitor Lewkowycz , Erica Moreira , Rewon Child , Oleksandr Polozov , Katherine Lee , Zongwei Zhou , Xuezhi Wang , Brennan Saeta , Mark D\u00edaz , Orhan Firat , Michele Catasta , Jason Wei , Kathleen S. Meier-Hellstern , Douglas Eck , Jeff Dean , Slav Petrov , Noah Fiedel . Palm : Scaling language modeling pathways . ArXiv , abs/2204.02311 , 2022 . 11 [ 9 ] Deborah A. Dahl , Madeleine Bates , Michael Brown , William Fisher , Kate Hunicke-Smith , David Pallett , Christine Pao , Alexander Rudnicky , Elizabeth Shriberg . Expanding scope ATIS task :",
    "[ 9 ] Deborah A. Dahl , Madeleine Bates , Michael Brown , William Fisher , Kate Hunicke-Smith , David Pallett , Christine Pao , Alexander Rudnicky , Elizabeth Shriberg . Expanding scope ATIS task : ATIS-3 corpus . Human Language Technology : Proceedings Workshop held Plainsboro , New Jersey , March 8-11 , 1994 , 1994 . [ 10 ] Longxu Dou , Yan Gao , Xuqi Liu , Mingyang Pan , Dingzirui Wang , Wanxiang Che , Dechen Zhan , Min-Yen Kan , Jian-Guang Lou . Towards knowledge-intensive text-to-SQL semantic parsing formulaic knowledge . Proceedings 2022 Conference Empirical Methods Natural Language Processing , pages 5240\u20135253 , Abu Dhabi , United Arab Emirates , December 2022 . Association Computational Linguistics . [ 11 ] Yujian Gan , Xinyun Chen , Qiuping Huang , Matthew Purver , John R. Woodward , Jinxia Xie , Pengsheng Huang . Towards robustness text-to-sql models synonym substitution . Chengqing Zong , Fei Xia , Wenjie Li , Roberto Navigli , editors , Proceedings 59th Annual Meeting",
    ", Jinxia Xie , Pengsheng Huang . Towards robustness text-to-sql models synonym substitution . Chengqing Zong , Fei Xia , Wenjie Li , Roberto Navigli , editors , Proceedings 59th Annual Meeting Association Computational Linguistics 11th International Joint Conference Natural Language Processing , ACL/IJCNLP 2021 , ( Volume 1 : Long Papers ) , Virtual Event , August 1-6 , 2021 , pages 2505\u20132515 . Association Computational Linguistics , 2021. doi : 10.18653/v1/2021.acl-long.195 . [ 12 ] Jiaqi Guo , Zecheng Zhan , Yan Gao , Yan Xiao , Jian-Guang Lou , Ting Liu , Dongmei Zhang . Towards complex text-to-SQL cross-domain database intermediate representation . Proceedings 57th Annual Meeting Association Computational Linguistics , pages 4524\u20134535 , Florence , Italy , July 2019 . Association Computational Linguistics . doi : 10.18653/v1/P19-1444 . [ 13 ] Moshe Hazoom , Vibhor Malik , Ben Bogin . Text-to-SQL wild : naturally-occurring dataset based stack exchange data . Proceedings 1st Workshop",
    "Linguistics . doi : 10.18653/v1/P19-1444 . [ 13 ] Moshe Hazoom , Vibhor Malik , Ben Bogin . Text-to-SQL wild : naturally-occurring dataset based stack exchange data . Proceedings 1st Workshop Natural Language Processing Programming ( NLP4Prog 2021 ) , pages 77\u201387 , Online , August 2021 . Association Computational Linguistics . doi : 10.18653/v1/2021.nlp4prog-1.9 . [ 14 ] Joseph M. Hellerstein . Quantitative data cleaning large databases . Proceedings 2008 ACM SIGMOD international conference Management data , page 1197\u20131200 , 2008 . [ 15 ] Jie Huang , Hanyin Shao , Kevin Chen-Chuan Chang . large pre-trained language models leaking personal information ? Findings Association Computational Linguistics : EMNLP 2022 , pages 2038\u20132047 , Abu Dhabi , United Arab Emirates , December 2022 . Association Computational Linguistics . [ 16 ] Binyuan Hui , Ruiying Geng , Qiyu Ren , Binhua Li , Yongbin Li , Jian Sun , Fei Huang , Luo Si , Pengfei Zhu , Xiaodan Zhu . Dynamic hybrid relation exploration",
    "Computational Linguistics . [ 16 ] Binyuan Hui , Ruiying Geng , Qiyu Ren , Binhua Li , Yongbin Li , Jian Sun , Fei Huang , Luo Si , Pengfei Zhu , Xiaodan Zhu . Dynamic hybrid relation exploration network cross-domain context-dependent semantic parsing . Thirty-Fifth AAAI Conference Artificial Intelligence , AAAI 2021 , Thirty-Third Conference Innovative Applications Artificial Intelligence , IAAI 2021 , Eleventh Symposium Educational Advances Artificial Intelligence , EAAI 2021 , Virtual Event , February 2-9 , 2021 , pages 13116\u201313124 . AAAI Press , 2021 . [ 17 ] Binyuan Hui , Xiang Shi , Ruiying Geng , Binhua Li , Yongbin Li , Jian Sun , Xiaodan Zhu . Improving text-to-sql schema dependency learning . arXiv:2103.04399 , 2021 . [ 18 ] Binyuan Hui , Ruiying Geng , Lihan Wang , Bowen Qin , Yanyang Li , Bowen Li , Jian Sun , Yongbin Li . S2SQL : Injecting syntax question-schema interaction graph encoder text-to-SQL parsers . Findings Association Computational Linguistics : ACL 2022 ,",
    ", Yanyang Li , Bowen Li , Jian Sun , Yongbin Li . S2SQL : Injecting syntax question-schema interaction graph encoder text-to-SQL parsers . Findings Association Computational Linguistics : ACL 2022 , pages 1254\u20131262 , Dublin , Ireland , May 2022 . Association Computational Linguistics . doi : 10.18653/v1/2022.findings-acl.99 . [ 19 ] Ihab F. Ilyas Xu Chu . Trends cleaning relational data : Consistency deduplication . Foundations Trends Databases , 5:281\u2013393 , 2015 . [ 20 ] Srinivasan Iyer , Ioannis Konstas , Alvin Cheung , Jayant Krishnamurthy , Luke Zettlemoyer . Learning neural semantic parser user feedback . Proceedings 55th Annual Meeting Association Computational Linguistics ( Volume 1 : Long Papers ) , pages 963\u2013973 , Vancouver , Canada , July 2017 . Association Computational Linguistics . doi : 10.18653/v1/P17-1089 . 12 [ 21 ] Takeshi Kojima , Shixiang ( Shane ) Gu , Machel Reid , Yutaka Matsuo , Yusuke Iwasawa . Large language models zero-shot reasoners . Advances Neural",
    ". doi : 10.18653/v1/P17-1089 . 12 [ 21 ] Takeshi Kojima , Shixiang ( Shane ) Gu , Machel Reid , Yutaka Matsuo , Yusuke Iwasawa . Large language models zero-shot reasoners . Advances Neural Information Processing Systems , volume 35 , pages 22199\u201322213 , 2022 . [ 22 ] Jan Kossmann , Stefan Halfpap , Marcel Jankrift , Rainer Schlosser . Magic mirror hand , best land ? experimental evaluation index selection algorithms . Proceedings VLDB Endowment , 13 ( 12 ) :2382\u20132395 , 2020 . [ 23 ] Prerna S. Kulkarni Jagdish W. Bakal . Survey data cleaning . 2014 International Conference Advances Computing , Communications Informatics ( ICACCI ) , page 2361\u20132366 , 2014 . [ 24 ] Chia-Hsuan Lee , Oleksandr Polozov , Matthew Richardson . KaggleDBQA : Realistic evaluation text-to-SQL parsers . Proceedings 59th Annual Meeting Association Computational Linguistics 11th International Joint Conference Natural Language Processing ( Volume 1 : Long Papers ) , pages 2261\u20132273 , Online , August 2021 .",
    "59th Annual Meeting Association Computational Linguistics 11th International Joint Conference Natural Language Processing ( Volume 1 : Long Papers ) , pages 2261\u20132273 , Online , August 2021 . Association Computational Linguistics . [ 25 ] Gyubok Lee , Hyeonji Hwang , Seongsu Bae , Yeonsu Kwon , Woncheol Shin , Seongjun Yang , Minjoon Seo , Jong-Yeup Kim , Edward Choi . Ehrsql : practical text-to-sql benchmark electronic health records . S. Koyejo , S. Mohamed , A. Agarwal , D. Belgrave , K. Cho , A. Oh , editors , Advances Neural Information Processing Systems , volume 35 , pages 15589\u201315601 . Curran Associates , Inc. , 2022 . [ 26 ] Dandan Li , Lu Han , Yi Ding . Sql query optimization methods relational database system . In2010 Second International Conference Computer Engineering Applications , volume 1 , pages 557\u2013560 . IEEE , 2010 . [ 27 ] Jinyang Li , Binyuan Hui , Reynold Cheng , Bowen Qin , Chenhao , Nan Huo , Fei Huang , Wenyu Du , Luo Si , Yongbin Li . Graphix-t5 : Mixing",
    ", volume 1 , pages 557\u2013560 . IEEE , 2010 . [ 27 ] Jinyang Li , Binyuan Hui , Reynold Cheng , Bowen Qin , Chenhao , Nan Huo , Fei Huang , Wenyu Du , Luo Si , Yongbin Li . Graphix-t5 : Mixing pre-trained transformers graph- aware layers text-to-sql parsing . ArXiv , abs/2301.07507 , 2023 . [ 28 ] Tanzim Mahmud , KM Azharul Hasan , Mahtab Ahmed , Thwoi Hla Ching Chak . rule based approach nlp based query processing . 2015 2nd International Conference Electrical Information Communication Technologies ( EICT ) , pages 78\u201382 . IEEE , 2015 . [ 29 ] Gr\u00e9goire Mialon , Roberto Dess\u00ec , Maria Lomeli , Christoforos Nalmpantis , Ramakanth Pasunuru , Roberta Raileanu , Baptiste Rozi\u00e8re , Timo Schick , Jane Dwivedi-Yu , Asli Celikyilmaz , Edouard Grave , Yann LeCun , Thomas Scialom . Augmented language models : survey . ArXiv , abs/2302.07842 , 2023 . [ 30 ] Vamsi Krishna Myalapalli ASN Chakravarthy . Revamping sql queries cost based optimization . 2016 International Conference Circuits , Controls ,",
    ": survey . ArXiv , abs/2302.07842 , 2023 . [ 30 ] Vamsi Krishna Myalapalli ASN Chakravarthy . Revamping sql queries cost based optimization . 2016 International Conference Circuits , Controls , Communications Computing ( I4C ) , pages 1\u20136 . IEEE , 2016 . [ 31 ] Paulo H. Oliveira , Daniel dos Santos Kaster , Caetano Traina , Ihab F. Ilyas . Batchwise probabilistic incremental data cleaning . ArXiv , abs/2011.04730 , 2020 . [ 32 ] OpenAI . Gpt-4 technical report . ArXiv , abs/2303.08774 , 2023 . [ 33 ] Long Ouyang , Jeff Wu , Xu Jiang , Diogo Almeida , Carroll L. Wainwright , Pamela Mishkin , Chong Zhang , Sandhini Agarwal , Katarina Slama , Alex Ray , John Schulman , Jacob Hilton , Fraser Kelton , Luke E. Miller , Maddie Simens , Amanda Askell , Peter Welinder , Paul Francis Christiano , Jan Leike , Ryan J. Lowe . Training language models follow instructions human feedback . ArXiv , abs/2203.02155 , 2022 . [ 34 ] Hamid Pirahesh , Joseph M. Hellerstein , Waqar Hasan . Extensible/rule",
    "Jan Leike , Ryan J. Lowe . Training language models follow instructions human feedback . ArXiv , abs/2203.02155 , 2022 . [ 34 ] Hamid Pirahesh , Joseph M. Hellerstein , Waqar Hasan . Extensible/rule based query rewrite optimization starburst . Proceedings ACM SIGMOD International Conference Management Data , pages 39\u201348 , 1992 . [ 35 ] Mohammadreza Pourreza Davood Rafiei . DIN-SQL : decomposed in-context learning text-to-sql self-correction . CoRR , abs/2304.11015 , 2023. doi : 10.48550/arXiv.2304.11015 . 13 [ 36 ] Jiexing Qi , Jingyao Tang , Ziwei , Xiangpeng Wan , Yu Cheng , Chenghu Zhou , Xinbing Wang , Quanshi Zhang , Zhouhan Lin . RASAT : Integrating relational structures pretrained Seq2Seq model text-to-SQL . Proceedings 2022 Conference Empirical Meth- ods Natural Language Processing , pages 3215\u20133229 , Abu Dhabi , United Arab Emirates , December 2022 . Association Computational Linguistics . [ 37 ] Bowen Qin , Binyuan Hui , Lihan Wang , Min Yang , Jinyang Li , Binhua Li ,",
    ", pages 3215\u20133229 , Abu Dhabi , United Arab Emirates , December 2022 . Association Computational Linguistics . [ 37 ] Bowen Qin , Binyuan Hui , Lihan Wang , Min Yang , Jinyang Li , Binhua Li , Ruiying Geng , Rongyu Cao , Jian Sun , Luo Si , Fei Huang , Yongbin Li . survey text-to-sql parsing : Concepts , methods , future directions . arXiv:2208.13629 , 2022 . [ 38 ] Colin Raffel , Noam Shazeer , Adam Roberts , Katherine Lee , Sharan Narang , Michael Matena , Yanqi Zhou , Wei Li , Peter J. Liu . Exploring limits transfer learning unified text-to-text transformer . Journal Machine Learning Research , 21 ( 140 ) :1\u201367 , 2020 . [ 39 ] Nitarshan Rajkumar , Raymond Li , Dzmitry Bahdanau . Evaluating text-to-sql capabilities large language models . ArXiv , abs/2204.00498 , 2022 . [ 40 ] Torsten Scholak , Nathan Schucher , Dzmitry Bahdanau . PICARD : Parsing incrementally constrained auto-regressive decoding language models . Proceedings 2021 Con- ference Empirical Methods Natural Language",
    "Scholak , Nathan Schucher , Dzmitry Bahdanau . PICARD : Parsing incrementally constrained auto-regressive decoding language models . Proceedings 2021 Con- ference Empirical Methods Natural Language Processing , pages 9895\u20139901 , Online Punta Cana , Dominican Republic , November 2021 . Association Computational Linguistics . [ 41 ] Peter Shaw , Ming-Wei Chang , Panupong Pasupat , Kristina Toutanova . Compositional generalization natural language variation : semantic parsing approach handle ? InProceedings 59th Annual Meeting Association Computational Linguistics 11th International Joint Conference Natural Language Processing ( Volume 1 : Long Papers ) , pages 922\u2013938 , Online , August 2021 . Association Computational Linguistics . [ 42 ] Alon Talmor , Ori Yoran , Ronan Le Bras , Chandra Bhagavatula , Yoav Goldberg , Yejin Choi , Jonathan Berant . Commonsenseqa 2.0 : Exposing limits ai gamification . J. Vanschoren S. Yeung , editors , Proceedings Neural Information Processing Systems",
    "Bhagavatula , Yoav Goldberg , Yejin Choi , Jonathan Berant . Commonsenseqa 2.0 : Exposing limits ai gamification . J. Vanschoren S. Yeung , editors , Proceedings Neural Information Processing Systems Track Datasets Benchmarks , volume 1 . Curran , 2021 . [ 43 ] Bailin Wang , Richard Shin , Xiaodong Liu , Oleksandr Polozov , Matthew Richardson . RAT- SQL : Relation-aware schema encoding linking text-to-SQL parsers . Proceedings 58th Annual Meeting Association Computational Linguistics , pages 7567\u20137578 , Online , July 2020 . Association Computational Linguistics . [ 44 ] Lihan Wang , Bowen Qin , Binyuan Hui , Bowen Li , Min Yang , Bailin Wang , Binhua Li , Jian Sun , Fei Huang , Luo Si , Yongbin Li . Proton : Probing schema linking information pre-trained language models text-to-sql parsing . Aidong Zhang Huzefa Rangwala , editors , KDD \u2019 22 : 28th ACM SIGKDD Conference Knowledge Discovery Data Mining , Washington , DC , USA , August 14 - 18 , 2022 , pages 1889\u20131898 . ACM , 2022. doi :",
    ". Aidong Zhang Huzefa Rangwala , editors , KDD \u2019 22 : 28th ACM SIGKDD Conference Knowledge Discovery Data Mining , Washington , DC , USA , August 14 - 18 , 2022 , pages 1889\u20131898 . ACM , 2022. doi : 10.1145/3534678.3539305 . [ 45 ] Lijie Wang , Ao Zhang , Kun Wu , Ke Sun , Zhenghua Li , Hua Wu , Min Zhang , Haifeng Wang . DuSQL : large-scale pragmatic Chinese text-to-SQL dataset . Proceedings 2020 Conference Empirical Methods Natural Language Processing ( EMNLP ) , pages 6923\u20136935 , Online , November 2020 . Association Computational Linguistics . [ 46 ] Ping Wang , Tian Shi , Chandan K. Reddy . Text-to-sql generation question answering electronic medical records . Proceedings Web Conference 2020 , 2020 . [ 47 ] Zhaoguo Wang , Zhou Zhou , Yicun Yang , Haoran Ding , Gansen Hu , Ding Ding , Chuzhe Tang , Haibo Chen , Jinyang Li . Wetune : Automatic discovery verification query rewrite rules . Proceedings 2022 International Conference Management Data , pages 94\u2013107 , 2022 . [ 48 ] Jason",
    "Chuzhe Tang , Haibo Chen , Jinyang Li . Wetune : Automatic discovery verification query rewrite rules . Proceedings 2022 International Conference Management Data , pages 94\u2013107 , 2022 . [ 48 ] Jason Wei , Xuezhi Wang , Dale Schuurmans , Maarten Bosma , Ed Huai hsin Chi , F. Xia , Quoc Le , Denny Zhou . Chain thought prompting elicits reasoning large language models . ArXiv , abs/2201.11903 , 2022 . 14 [ 49 ] Tianbao Xie , Chen Henry Wu , Peng Shi , Ruiqi Zhong , Torsten Scholak , Michihiro Yasunaga , Chien-Sheng Wu , Ming Zhong , Pengcheng Yin , Sida I. Wang , Victor Zhong , Bailin Wang , Chengzu Li , Connor Boyle , Ansong Ni , Ziyu Yao , Dragomir Radev , Caiming Xiong , Lingpeng Kong , Rui Zhang , Noah A. Smith , Luke Zettlemoyer , Tao Yu . UnifiedSKG : Unifying multi-tasking structured knowledge grounding text-to-text language models . Proceedings 2022 Conference Empirical Methods Natural Language Processing , pages 602\u2013631 , Abu Dhabi , United Arab Emirates , December 2022 .",
    "knowledge grounding text-to-text language models . Proceedings 2022 Conference Empirical Methods Natural Language Processing , pages 602\u2013631 , Abu Dhabi , United Arab Emirates , December 2022 . Association Computational Linguistics . [ 50 ] Xiaojun Xu , Chang Liu , Dawn Song . Sqlnet : Generating structured queries natural language without reinforcement learning . ArXiv preprint , 2017 . [ 51 ] Navid Yaghmazadeh , Yuepeng Wang , Isil Dillig , Thomas Dillig . Sqlizer : query synthesis natural language . Proceedings ACM Programming Languages , 1 ( OOPSLA ) : 1\u201326 , 2017 . [ 52 ] Tao Yu , Zifan Li , Zilin Zhang , Rui Zhang , Dragomir Radev . TypeSQL : Knowledge-based type-aware neural text-to-SQL generation . Proceedings 2018 Conference North American Chapter Association Computational Linguistics : Human Language Technologies , Volume 2 ( Short Papers ) , page 588\u2013594 , 2018 . [ 53 ] Tao Yu , Rui Zhang , Kai Yang , Michihiro Yasunaga , Dongxu Wang , Zifan Li , James , Irene Li , Qingning",
    ": Human Language Technologies , Volume 2 ( Short Papers ) , page 588\u2013594 , 2018 . [ 53 ] Tao Yu , Rui Zhang , Kai Yang , Michihiro Yasunaga , Dongxu Wang , Zifan Li , James , Irene Li , Qingning Yao , Shanelle Roman , Zilin Zhang , Dragomir Radev . Spider : large-scale human-labeled dataset complex cross-domain semantic parsing text-to-SQL task . InProceedings 2018 Conference Empirical Methods Natural Language Processing , page 3911\u20133921 , 2018 . [ 54 ] Tao Yu , Rui Zhang , Alex Polozov , Christopher Meek , Ahmed Hassan Awadallah . Score : Pre-training context representation conversational semantic parsing . 9th International Conference Learning Representations , ICLR 2021 , Virtual Event , Austria , May 3-7 , 2021 . OpenReview.net , 2021 . [ 55 ] John M. Zelle Raymond J. Mooney . Learning parse database queries using inductive logic programming . Proceedings Fourteenth National Conference Artificial Intelligence Ninth Conference Innovative Applications Artificial Intelligence , pages",
    "parse database queries using inductive logic programming . Proceedings Fourteenth National Conference Artificial Intelligence Ninth Conference Innovative Applications Artificial Intelligence , pages 1050\u20131055 , 1996 . [ 56 ] Susan Zhang , Stephen Roller , Naman Goyal , Mikel Artetxe , Moya Chen , Shuohui Chen , Christopher Dewan , Mona Diab , Xian Li , Xi Victoria Lin , Todor Mihaylov , Myle Ott , Sam Shleifer , Kurt Shuster , Daniel Simig , Punit Singh Koura , Anjali Sridhar , Tianlu Wang , Luke Zettlemoyer . Opt : Open pre-trained transformer language models . ArXiv , abs/2205.01068 , 2022 . [ 57 ] Chen Zhao , Yu Su , Adam Pauls , Emmanouil Antonios Platanios . Bridging generalization gap text-to-SQL parsing schema expansion . Proceedings 60th Annual Meeting Association Computational Linguistics ( Volume 1 : Long Papers ) , pages 5568\u20135578 , Dublin , Ireland , May 2022 . Association Computational Linguistics . [ 58 ] Victor Zhong , Caiming Xiong , Richard Socher . Seq2SQL :",
    "Linguistics ( Volume 1 : Long Papers ) , pages 5568\u20135578 , Dublin , Ireland , May 2022 . Association Computational Linguistics . [ 58 ] Victor Zhong , Caiming Xiong , Richard Socher . Seq2SQL : Generating structured queries natural language using reinforcement learning . CoRR abs/1709.00103 , 2017 . [ 59 ] Victor Zhong , Mike Lewis , Sida I. Wang , Luke Zettlemoyer . Grounded adaptation zero-shot executable semantic parsing . Bonnie Webber , Trevor Cohn , Yulan , Yang Liu , editors , Proceedings 2020 Conference Empirical Methods Natural Language Processing , EMNLP 2020 , Online , November 16-20 , 2020 , pages 6869\u20136882 . Association Computational Linguistics , 2020. doi : 10.18653/v1/2020.emnlp-main.558 . [ 60 ] Rong Zhou . Research key performance index prediction distributed database based machine learning algorithm . Proceedings 2nd International Conference Cognitive Based Information Processing Applications ( CIPA 2022 ) Volume 2 , pages 563\u2013567 . Springer , 2023 . [ 61 ] Xuanhe",
    "machine learning algorithm . Proceedings 2nd International Conference Cognitive Based Information Processing Applications ( CIPA 2022 ) Volume 2 , pages 563\u2013567 . Springer , 2023 . [ 61 ] Xuanhe Zhou , Guoliang Li , Chengliang Chai , Jianhua Feng . learned query rewrite system using monte carlo tree search . Proceedings VLDB Endowment , 15 ( 1 ) :46\u201358 , 2021. doi : 10.14778/3485450.3485456 . 15 [ 62 ] Xuanhe Zhou , Chengliang Chai , Guoliang Li , Ji Sun . Database meets artificial intelligence : survey . IEEE Transactions Knowledge Data Engineering , 34 ( 3 ) :1096\u20131116 , 2022. doi : 10.1109/TKDE.2020.2994641 . 16A Datasheet Datasets follow instructions provided Datasheet Datasets answer important ques- tions considering dataset . A.1 Motivation purpose dataset created ? advancement Large Language Models ( LLMs ) raised concerns regarding whether state-of-the-art LLMs , ChatGPT Codex , replace human effort real-world text-to-SQL tasks involving large database values . exceptional",
    "Language Models ( LLMs ) raised concerns regarding whether state-of-the-art LLMs , ChatGPT Codex , replace human effort real-world text-to-SQL tasks involving large database values . exceptional performance previous academic tasks like SPIDER impresses researchers . However , observe current cross-domain text-to-SQL benchmarks focus database schema , lacks full attention values , resulting gap academic real-world applications . address issue , introduce BIRD , largest cross-domain text-to-SQL benchmark highlighting extensive realistic databases community development . Additionally , hope observe performance gap LLMs humans . experimental results indicate , , LLMs still unable replace human effort . far know , BIRDis first text-to-SQL benchmark collect human performance . created dataset ( e.g. , team , research group ) behalf entity ( e.g. , company , institution , organization ) ? Please refer author list details . research team involves Star Lab University Hong Kong , Alibaba DAMO",
    "( e.g. , team , research group ) behalf entity ( e.g. , company , institution , organization ) ? Please refer author list details . research team involves Star Lab University Hong Kong , Alibaba DAMO Academy Conversational AI ( ConAI ) Team , Department Computer Science University Illinois Urbana-Champaign , Department EECS Massachusetts Institute Technology , School Data Science Chinese University Hong Kong ( Shenzhen ) , Database Group Tsinghua University . funded creation dataset ? dataset fully funded Alibaba DAMO Academy ConAI team . spent 97,654 USD presenting data . budget includes 10 % recruiting competent research interns , 80 % developing benchmark , 10 % refining implementing benchmark . A.2 Composition instances comprise dataset represent ( e.g. , documents , photos , people , countries ) ? BIRDcontains natural language questions , external knowledge evidence sentences , processed large databases , database description files ( csv ) , SQL queries . many instances total (",
    ", countries ) ? BIRDcontains natural language questions , external knowledge evidence sentences , processed large databases , database description files ( csv ) , SQL queries . many instances total ( type , appropriate ) ? BIRDcontains 12,751 natural language questions , 12,751 external knowledge evidence sentences , 95 processed large databases , 95 folders database description CSV files , 12,751 ground truth SQL queries . dataset contain possible instances sample ( necessarily random ) instances larger set ? InBIRD , divide three sets : training , development , testing . Training development sets public testing data set hidden fair evaluation text-to-SQL challengers . could witness real development text-to-SQLs LLM era . label target associated instance ? InBIRD , provide two labels question instance : SQLs ( target input ) external knowledge evidence ( expert annotated evidence expected SQL ) . information missing individual instances ? . relationships individual instances made",
    "question instance : SQLs ( target input ) external knowledge evidence ( expert annotated evidence expected SQL ) . information missing individual instances ? . relationships individual instances made explicit ( e.g. , users \u2019 movie ratings , social network links ) ? . recommended data splits ? data consists 9,428 instances training set , 1,534 instances development set , 1,789 instances concealed test set . training 17and development sets derived public databases , test set databases curated designed specialized team . researchers express concerns remarkable performance LLMs text-to-SQL tasks may attributed improvement capabilities , rather exposure data database values LLMs pre-training phase . address concerns , opt self-design new databases testing using actual tabular data , thereby ensuring LLMs preview databases . errors , sources noise , redundancies dataset ? stated main content , double-blind annotation procedure expensive rigorous , ensuring data quality . However ,",
    "ensuring LLMs preview databases . errors , sources noise , redundancies dataset ? stated main content , double-blind annotation procedure expensive rigorous , ensuring data quality . However , virtually impossible dataset , especially complex ones , entirely free errors . team committed enhancing data even paper accepted , thereby contributing text-to-SQL community . addition , encourage users provide feedback report errors data website , allowing us rectify enhance dataset . dataset self-contained , link otherwise rely external resources ( e.g. , websites , tweets , datasets ) ? Yes , databases training development collected appropriate licenses . Please see Section 3.2 details dataset contain data might considered confidential ( e.g. , data pro- tected legal privilege doctor-patient confidentiality , data includes content individuals \u2019 non-public communications ) ? . dataset contain data , viewed directly , might offensive , insulting , threatening , might otherwise cause anxiety ?",
    ", data includes content individuals \u2019 non-public communications ) ? . dataset contain data , viewed directly , might offensive , insulting , threatening , might otherwise cause anxiety ? . dataset identify subpopulations ( e.g. , age , gender ) ? questions mention ages genders , used detect capability models text-to-SQLs . bias opinions involved . possible identify individuals ( i.e. , one natural persons ) , either directly indirectly ( i.e. , combination data ) dataset ? . databases collected open-sourced platforms , sensitive data already processed . dataset contain data might considered sensitive way ( e.g. , data reveals race ethnic origins , sexual orientations , religious beliefs , political opinions union memberships , locations ; financial health data ; biometric genetic data ; forms government identification , social security numbers ; criminal history ) ? , QA-based text-to-SQL dataset , \u2019 require models deliver opinions results . also \u2019 present bias opinions dataset . A.3",
    "government identification , social security numbers ; criminal history ) ? , QA-based text-to-SQL dataset , \u2019 require models deliver opinions results . also \u2019 present bias opinions dataset . A.3 Collection Process data associated instance acquired ? Section 3 Appendix B.2 introduce detail . mechanisms procedures used collect data ( e.g. , hardware apparatuses sensors , manual human curation , software programs , software APIs ) ? Section 3 Appendix B.2 introduce detail . crowdworkers use Alibaba internal labeling software annotate data examine results . dataset sample larger set , sampling strategy ( e.g. , deterministic , probabilistic specific sampling probabilities ) ? . involved data collection process ( e.g. , students , crowdworkers , contractors ) compensated ( e.g. , much crowdworkers paid ) ? Four PhD students two MS students involved creation database description files . Two independent teams crowdworkers recruited annotate questions SQLs . question annotators composed 11",
    "paid ) ? Four PhD students two MS students involved creation database description files . Two independent teams crowdworkers recruited annotate questions SQLs . question annotators composed 11 English native speakers SQL annotators comprised database engineers DB students . total consumption 97,654 USD . 18Over timeframe data collected ? Sep. 2022 Mar . 2023 . ethical review processes conducted ( e.g. , institutional review board ) ? Yes , take issues seriously . review process , found certain questions related politics inappropriate language . addressed concerns modifying content providing serious warning annotators responsible instances . collect data individuals question directly , obtain via third parties sources ( e.g. , websites ) ? Section 3 Appendix B.2 introduce detail . individuals question notified data collection ? Yes . individuals question consent collection use data ? Sure , recruited paid satisfying salaries . consent obtained , consenting individuals provided",
    "individuals question notified data collection ? Yes . individuals question consent collection use data ? Sure , recruited paid satisfying salaries . consent obtained , consenting individuals provided mechanism revoke consent future certain uses ? . analysis potential impact dataset use data subjects ( e.g. , data protection impact analysis ) conducted ? Yes , comprehensive analysis including error analysis , efficiency analysis , experiments paper Appendix . A.4 Preprocessing/cleaning/labeling preprocessing/cleaning/labeling data done ( e.g. , discretization bucketing , tokenization , part-of-speech tagging , SIFT feature extraction , removal instances , processing missing values ) ? Yes , provide token list question SQLs NLTK users . \u201c raw \u201d data saved addition preprocessed/cleaned/labeled data ( e.g. , support unanticipated future uses ) ? . software used preprocess/clean/label data available ? Yes , https : //www.nltk.org/ A.5 Uses dataset used tasks already ? . repository links",
    "data ( e.g. , support unanticipated future uses ) ? . software used preprocess/clean/label data available ? Yes , https : //www.nltk.org/ A.5 Uses dataset used tasks already ? . repository links papers systems use dataset ? . ( ) tasks could dataset used ? Sure , databases analysis-style questions valuable , could beneficial DB-based code generation , data science analysis , etc . anything composition dataset way collected prepro- cessed/cleaned/labeled might impact future uses ? . tasks dataset used ? . A.6 Distribution dataset distributed third parties outside entity ( e.g. , company , institution , organization ) behalf dataset created ? . dataset distributed ( e.g. , tarball website , API , GitHub ) ? source codings datasets could found leaderboard website : https : //bird-bench . github.io/ . provide fast download links convenience researchers want use big data . Furthermore , code repository found https : //github.com/ AlibabaResearch/DAMO-ConvAI/tree/main/bird 19When dataset",
    ". provide fast download links convenience researchers want use big data . Furthermore , code repository found https : //github.com/ AlibabaResearch/DAMO-ConvAI/tree/main/bird 19When dataset distributed ? . dataset distributed copyright intellectual property ( IP ) license , and/or applicable terms use ( ToU ) ? Given database size BIRDis largest , afraid abusing ample database values may lead inappropriate commercial use . Therefore , claim dataset distributed CC BY-NC 4.0 . third parties imposed IP-based restrictions data associated instances ? . export controls regulatory restrictions apply dataset individual instances ? . A.7 Maintenance supporting/hosting/maintaining dataset ? HKU STAR LAB Alibaba DAMO Academy owner/curator/manager dataset contacted ( e.g. , email address ) ? Contact bird.bench23 @ gmail.com corresponding authors co-first authors author list . erratum ? . dataset updated ( e.g. , correct labeling errors , add new instances , delete instances ) ? Yes , keep",
    "bird.bench23 @ gmail.com corresponding authors co-first authors author list . erratum ? . dataset updated ( e.g. , correct labeling errors , add new instances , delete instances ) ? Yes , keep polishing optimizing data periodically . dataset relates people , applicable limits retention data associated instances ( e.g. , individuals question told data would retained fixed period time deleted ) ? . older versions dataset continue supported/hosted/maintained ? . updated version reliable . others want extend/augment/build on/contribute dataset , mechanism ? Yes , contact authors first . 20B Appendix B.1 Text-to-SQL Difficulty order help researchers deeply analyze model performance various text-to-SQL case levels , class examples simple ( 30 % ) , moderate ( 60 % ) , challenging ( 10 % ) . Previous work , SPIDER , computed difficulty mainly based SQL complexity . However , find additional factors , question comprehension , schema linking , external knowledge reasoning , also influence",
    "Previous work , SPIDER , computed difficulty mainly based SQL complexity . However , find additional factors , question comprehension , schema linking , external knowledge reasoning , also influence model human performance . Therefore , SQL annotator required evaluate examples based factors , experts conclude ratings divide examples three aforementioned difficulty levels . approach offers extensive difficulty analysis text-to-SQL tasks . performance ChatGPT three different difficulty levels shown Table B.1 . take approach human scoring established rules . detailed crowdsourcing rule employed rate difficulty SQL annotators generate SQLs question . process consists evaluating four dimensions : process consists evaluating four dimensions : 1.Question Understanding : discrete scale 1 3 , annotators assess ambiguity difficulty comprehending question \u2019 intent , 1 straightforward , 2 clear requiring thought , 3 extremely ambiguous . 2.Knowledge Reasoning : discrete scale 1 3 , annotators",
    "assess ambiguity difficulty comprehending question \u2019 intent , 1 straightforward , 2 clear requiring thought , 3 extremely ambiguous . 2.Knowledge Reasoning : discrete scale 1 3 , annotators rate amount external knowledge required map question SQL , 1 indicating knowledge required , 2 requiring evidence external knowledge generating SQLs easy understand , 3 requiring extensive knowledge much thoughts . 3.Data Complexity : Annotators rate complexity schema relations data size need analyzing discrete scale 1-3 , 1 simple schema data , 2 complex schema values understandable database description files , 3 highly complex difficult comprehend values schema even description files . 4.SQL Complexity : Annotators rate syntactic complexity target SQL query discrete scale 1-3 , 1 simple SQL without many keywords , 2 complicated 1 , 3 highly complex SQL many functions dimension considered equally important text-to-SQL annotations . SQLs ranked based scores , present simple , moderate , challenging",
    "keywords , 2 complicated 1 , 3 highly complex SQL many functions dimension considered equally important text-to-SQL annotations . SQLs ranked based scores , present simple , moderate , challenging difficulties proportions 30 % , 60 % , 10 % , respectively . MODELDEVSET TEST SET simple moderate challenging total simple moderate challenging total ( EX ) ChatGPT 31.08 13.29 12.08 24.05 35.41 19.46 12.28 26.77 ( EX ) ChatGPT + KG 45.44 26.14 19.01 37.22 49.21 31.89 20.70 39.30 ( VES ) ChatGPT 36.20 15.43 14.42 27.97 50.09 24.71 15.39 36.68 ( VES ) ChatGPT + KG 54.71 28.16 22.80 43.81 65.06 41.21 25.81 51.40 Table 4 : Execution Accuracy ( EX ) Valid Efficiency Score ( VES ) presented ChatGPT model version grounding ( KG ) external knowledge evidence , taking consideration development testing datasets . B.2 Annotation Entrance Annotation Platform Compensation . data collected Alibaba-Appen\u00a7 , internal version . Question annotator receives $ 0.6 reward validated question , SQL annotators",
    "datasets . B.2 Annotation Entrance Annotation Platform Compensation . data collected Alibaba-Appen\u00a7 , internal version . Question annotator receives $ 0.6 reward validated question , SQL annotators earn $ 1 per SQL contribution . also invite text-to-SQL experts professors join check annotate external knowledge evidence without compensation . ~1340 SQLs confirmed per week . \u00a7https : //appen.com/crowd-2/ # crowd 21Text-to-SQL Experts . three full-time text-to-SQL experts project : ( 1 ) . database research scientist \u2019 published 20 top DB conference papers ( e.g. , SIGMOD , VLDB ) . ( 2 ) . PhD student research interests text-to-SQL , achieved state-of-the-art results text-to- SQL open challenges . ( 3 ) . DBA engineer 10 years experience text-to-SQL applications B2B B2C businesses . Question Annotation Entrance . hire group native speakers English degrees bachelor \u2019 level database-related knowledge ask variety natural language questions regarding values databases . fulfill objective ,",
    "Annotation Entrance . hire group native speakers English degrees bachelor \u2019 level database-related knowledge ask variety natural language questions regarding values databases . fulfill objective , adopted following procedure : ( 1 ) . ER diagrams database description files documented assist annotators understanding databases ; ( 2 ) . present annotators three databases different domains require generate 10 questions database ; ( 3 ) . questions assessed 3 text-to-SQL experts applying predefined rules . questions earning least two votes marked valid . annotators capable generating less 8 valid questions per database preserved . result , 11 native speakers contribute questions B IRD . SQL Annotation Entrance . purpose enhancing quality SQL queries , assemble team skilled data engineers database students . team undergoes rigorous testing text-to-SQL evaluation process , assesses capability generating SQL queries variety questions facing different domains databases . annotator asked",
    "database students . team undergoes rigorous testing text-to-SQL evaluation process , assesses capability generating SQL queries variety questions facing different domains databases . annotator asked answer 10 questions , score least 9 10 qualified annotate SQL queries BIRD . B.3 Question Distribution Figure 8 contains detailed question types examples . B.4 Experiment Details FT-based Models . T5 strong versatile pre-trained language model ( PLM ) text- to-text generation achieved state-of-the-art performance variety semantic parsing tasks , including text-to-SQL . concatenate question serialized database schema input [ 40,49,41 ] . SQL fetched end-to-end fashion easily fine-tuning . seq2AST- based methods [ 43,5 ] also effective text-to-SQL , actually grammar rules utilized decoding constrained specific datasets [ 25 ] . implement codes mainly based hugging-face transformers library\u00b6 . set max input length 1024 , generation max length 512 , batch size 32 . also adopt Adafactor primary",
    "specific datasets [ 25 ] . implement codes mainly based hugging-face transformers library\u00b6 . set max input length 1024 , generation max length 512 , batch size 32 . also adopt Adafactor primary optimizer linear decayed learning rate 5e-5 . experiments conducted one NVIDIA Tesla A100 80GB , available research centers . set random seed 1 runs FT-based models since 1 optimal seed proven previous SOTA models [ 27 , 49 ] . ICL-based Models . Codex ( code-davinci-002 ) ChatGPT ( gpt-3.5-turbo ) pop- ular powerful large-scale pre-trained language models ( LLMs ) code generation driven ICL . produce multiple types codes , including SQL , human instructions without additional training . employ programming-based prompts , described [ 39 ] , collect results calling API . Also , choose Azure OpenAI API align codes variants LLMs . Given models allowed access unseen databases ground-truth SQLs evaluation set , zero-shot generation strategy appropriate . Moreover , investigate impact multi-step",
    "API align codes variants LLMs . Given models allowed access unseen databases ground-truth SQLs evaluation set , zero-shot generation strategy appropriate . Moreover , investigate impact multi-step reasoning LLMs BIRD , implement Chain-Of-Thought ( COT ) technique [ 48 ] easily adding prompt sentence `` Let \u2019 think step step . '' generation SQLs [ 21 ] . However , find output ChatGPT uncertain many unexpected explanations , thus provide 1-shot pseudo example ChatGPT learn procedure thinking output format . detailed prompt design shown Figure 9 . order minimize randomness results , set temperature 0 ensure reproduction . Knowledge Fusion . baseline implementation , naively concatenate knowledge evi- dence sentences questions database schemas , observe significant improvement \u00b6https : //huggingface.co/ 22Question TypeQuestion / SQLPercentageFundamentalRankingHow many gas stations CZE Premium gas ? SELECT COUNT ( GasStationID ) gasstations Country = 'CZE ' Segment = 'Premium'Sub",
    ": //huggingface.co/ 22Question TypeQuestion / SQLPercentageFundamentalRankingHow many gas stations CZE Premium gas ? SELECT COUNT ( GasStationID ) gasstations Country = 'CZE ' Segment = 'Premium'Sub TypeTypeMatch-basedWhat titles top 5 posts highest popularity ? SELECT Title posts ORDER ViewCount DESC LIMIT 5ComparisonHow many color cards borders ranked higher 12000 EDHRec ? SELECT COUNT ( id ) cards edhrecRank > 12000 borderColor = 'borderless'CountingHow many members ' hometowns Maryland state ? SELECT COUNT ( T2.member_id ) zip_code T1 INNER JOIN member T2 T1.zip_code = T2.zip T1.state = 'Maryland'AggregationName ID age patient two laboratory examinations show hematoclit level exceeded normal range.What average heightof superheroes Marvel Comics ? SELECT AVG ( T1.height_cm ) superhero T1 INNER JOIN publisher T2 T1.publisher_id = T2.id T2.publisher_name = 'Marvel Comics'ReasoningDomain KnowledgeSELECT T1.ID , STRFTIME ( ' % ' , CURRENT_TIMESTAMP ) - STRFTIME ( ' % ' , T1.Birthday )",
    "T1 INNER JOIN publisher T2 T1.publisher_id = T2.id T2.publisher_name = 'Marvel Comics'ReasoningDomain KnowledgeSELECT T1.ID , STRFTIME ( ' % ' , CURRENT_TIMESTAMP ) - STRFTIME ( ' % ' , T1.Birthday ) Patient T1 INNER JOIN Laboratory T2 T1.ID = T2.ID T1.ID ( SELECT ID Laboratory HCT > 52 GROUP ID COUNT ( ID ) > = 2 ) Numeric ComputationAmong posts score 20 , percentage owned elder user ? SELECT CAST ( SUM ( IIF ( T2.Age > 65 , 1 , 0 ) ) REAL ) * 100 / count ( T1.Id ) posts T1 INNER JOIN users T2 T1.OwnerUserId = T2.Id T1.Score > 20SynonymHow many clients opened accounts Jesenik branch women ? ( female ) SELECT COUNT ( T1.client_id ) client T1 INNER JOIN district T2 T1.district_id = T2.district_id T1.gender = ' F ' T2.A2 = 'Jesenik'Value IllustrationAmong weekly issuance accounts , many loan 200000 ? SELECT COUNT ( T1.account_id ) loan T1 INNER JOIN account T2 T1.account_id = T2.account_id T2.frequency = 'POPLATEK TYDNE ' T1.amount < 20000083.9 % 20.3 % 16.7 % 30.4 % 15.7 % 23.6 % 24.5",
    "200000 ? SELECT COUNT ( T1.account_id ) loan T1 INNER JOIN account T2 T1.account_id = T2.account_id T2.frequency = 'POPLATEK TYDNE ' T1.amount < 20000083.9 % 20.3 % 16.7 % 30.4 % 15.7 % 23.6 % 24.5 % 7.2 % 70.1 % TypeFigure 8 : Questions BIRD contain two main categories . Fundamental Type questions comparable text-to-SQL benchmarks . Reasoning Type questions requires external knowledge grounding answer . easy method . complicated effective strategy knowledge grounding ChatGPT T5 would important future topic . knowledge evidence sentences concluded external knowledge provided annotators described Section 3.3 . 23ICL Prompt InputCREATE TABLE singer ( singer_id TEXT null primary key , nation TEXT null , sname TEXT null , dname TEXT null , cname TEXT null , age INTEGER null , year INTEGER null , birth_year INTEGER null , salary REAL null , city TEXT null , phone_number INTEGER null , tax REAL null , ) -- External Knowledge : age = year - birth_year ; -- Using valid SQLite understading",
    "null , birth_year INTEGER null , salary REAL null , city TEXT null , phone_number INTEGER null , tax REAL null , ) -- External Knowledge : age = year - birth_year ; -- Using valid SQLite understading External Knowledge , answer following questions tables provided above.The final SQL : Let 's think step step.1 . referring external knowledge , need filter singers 'by year ' - 'birth_year ' > 27 ; 2. find singers step 1 nation = 'US ' , 3. use COUNT ( ) count many singers . Finally SQL : SELECT COUNT ( * ) singer year - birth_year > 27 ; < /s > 1-shot pseudo example CREATE TABLE customers ( CustomerID INTEGER UNIQUE null primary key , Segment TEXT null , Currency TEXT null ) CREATE TABLE gasstations ( GasStationID INTEGER UNIQUE null primary key , ChainID INTEGER null , Country TEXT null , Segment TEXT null ) CREATE TABLE products ( CREATE TABLE customers ( CustomerID INTEGER UNIQUE null primary key , Segment TEXT null , Currency TEXT null ) CREATE TABLE gasstations ( GasStationID",
    ", Segment TEXT null ) CREATE TABLE products ( CREATE TABLE customers ( CustomerID INTEGER UNIQUE null primary key , Segment TEXT null , Currency TEXT null ) CREATE TABLE gasstations ( GasStationID INTEGER UNIQUE null primary key , ChainID INTEGER null , Country TEXT null , Segment TEXT null ) CREATE TABLE yearmonth ( CustomerID INTEGER null , Date INTEGER null , Consumption REAL null , primary key ( CustomerID , Date ) , foreign key ( CustomerID ) references customers ( CustomerID ) ) \u2026\u2026Create DDL Prompt -- External Knowledge : August 2012 means Date contains '201208 ' yearmonth.date database ; Price per unit product = T1.Price / T1.Amount -- Using valid SQLite understading External Knowledge , answer following questions tables provided above. -- highest eligible free rate K-12 students schools Alameda County ? -- External Knowledge : August 2012 means Date contains '201208 ' yearmonth.date database ; Price per unit product = Price / Amount -- Using valid SQLite understading External",
    "Alameda County ? -- External Knowledge : August 2012 means Date contains '201208 ' yearmonth.date database ; Price per unit product = Price / Amount -- Using valid SQLite understading External Knowledge , answer following questions tables provided above. -- Forallthepeoplewhopaidmorethan29.00perunitofproductidNo.5.GivetheirconsumptionstatusintheAugustof2012 . final SQL : Let 's think step step.\\n1 . referring external knowledge , need calculate price per unit product id No.5 , T1.Price / T1.Amount ; 2. filter people paid 29.00 per unit product id No.5 ; 3. find consumption status people August 2012 . Finally SQL : SELECT yearmonth.Consumption transactions_1k T1 JOIN yearmonth T1.CustomerID = yearmonth.CustomerID T1.Date = yearmonth.Date T1.ProductID = 5 T1.Price final SQL : Let 's think step step.1 . referring external knowledge , need calculate price per unit product id No.5 , Price / Amount ; 2. filter people paid 29.00 per unit product id No.5 ; 3. find consumption status people",
    "step step.1 . referring external knowledge , need calculate price per unit product id No.5 , Price / Amount ; 2. filter people paid 29.00 per unit product id No.5 ; 3. find consumption status people August 2012.SELECT yearmonth.Consumption transactions_1k JOIN yearmonth transactions_1k.CustomerID = yearmonth.CustomerID transactions_1k.Date = yearmonth.Date transactions_1k.ProductID = 5 transactions_1k.Price / transactions_1k.Amount > 29.00 yearmonth.Date = \u2018 201208 \u2019 ; Knowledge Prompt Task Instruction 1-shot COT PromptChatGPT COT StepsQuestion Prompt SQL OutputFinally SQL : Figure 9 : detailed prompt design implementation ChatGPT + KG + COT . B.5 Efficiency Analysis Details Two strategies performing text-to-efficient-SQL presented Figure 10 . Examples show two-stage optimization embodied databases help semantic parsings generate efficient SQLs . B.6 Error Analysis Details Figure 11 presents detailed analysis errors made ChatGPT . B.7 Evaluation Details double-blind annotation BIRD ,",
    "databases help semantic parsings generate efficient SQLs . B.6 Error Analysis Details Figure 11 presents detailed analysis errors made ChatGPT . B.7 Evaluation Details double-blind annotation BIRD , encountered numerous ambiguous issues led mismatches , predominantly due unclear user intents . serious ambiguity use `` DISTINCT '' . annotators believe present unique values , names , cities , others argue used questions explicitly mention '' different '' '' distinctive '' . Therefore , use HashSet rather List compare final results since HashSet disregards row order automatically filters repetitive rows reduce am- biguity . However , may result false positives questions utilizing `` ORDER . '' identify three `` ORDER '' usage scenarios BIRD:1 ) Rank-based questions ( e.g. , `` Show top 5 students according math scores '' ) : order less important long results contain correct students . 2 ) Superlative questions : ( e.g. , `` List longest river USA '' ) : answer typically contains one item",
    "according math scores '' ) : order less important long results contain correct students . 2 ) Superlative questions : ( e.g. , `` List longest river USA '' ) : answer typically contains one item ( tied results ) , impact minimal . 3 ) Questions requiring specific order ( e.g. , `` Show top five students based math scores descending order '' ) : scenario explicitly requires correct ordering may lead false positives . However , in- stances uncommon , accounting less 1 % B IRD . 24Query RewritingEx1.1 Question : List age users located Vienna , Austria obtained badge ? ChatGPT SQL : SELECT Age users Location = 'Vienna , Austria \u2018 Id ( SELECT UserIdFROM badges ) Optimized SQL : ( time-saving percentage : 99.92 % ) SELECT u.AgeFROM users u INNER JOIN badgesAS bON u.Id= b.UserIdWHERE u.Location= 'Vienna , Austria \u2019 Take Away : applying JOINoperation instead subquery INcanimprove efficiency , database may execute JOINand filtering processes concurrently one operation without need store",
    "'Vienna , Austria \u2019 Take Away : applying JOINoperation instead subquery INcanimprove efficiency , database may execute JOINand filtering processes concurrently one operation without need store intermediate results filter primary query.Ex1.2 Question : many members ' hometowns Maryland state ? ChatGPT SQL : SELECT COUNT ( * ) member INNER JOIN zip_codeON member.zip= zip_code.zip_codeWHERE zip_code.state= 'Maryland \u2019 Optimized SQL : ( time-saving percentage : 67.93 % ) SELECT COUNT ( member.member_id ) member INNER JOIN zip_codeON member.zip= zip_code.zip_codeWHERE zip_code.state= 'Maryland \u2019 Take Away : Utilizing COUNTfunction NOT-NULLcolumn , opposed COUNT ( * ) , increase time efficiency . rewritten SQLenables database countNOT-NULLvalues within single column , rather computeall rows including NULLvalues . Usually , primary key column selected NOT-NULL column.Ex1.3 Question : owner account largest loan amount ? ChatGPT SQL : SELECT c.client_idFROM client c INNER JOIN dispd",
    "rows including NULLvalues . Usually , primary key column selected NOT-NULL column.Ex1.3 Question : owner account largest loan amount ? ChatGPT SQL : SELECT c.client_idFROM client c INNER JOIN dispd c.client_id= d.client_idINNER JOIN loan l d.account_id= l.account_id ORDER l.amountDESC LIMIT 1Optimized SQL : ( time-saving percentage : 62.39 % ) SELECT c.client_idFROM client c INNER JOIN dispd c.client_id= d.client_idINNER JOIN loan l d.account_id= l.account_idWHERE l.amount= ( SELECT MAX ( amount ) loan ) Take Away : unindexed environment , employing MAXfunction potentially yield faster results since avoids need sorting , could runagainst large table.Adding Indexes DatabaseEx2.1 Question : many accounts district \\ '' Pisek\\ '' ? ChatGPT SQL : SELECT COUNT ( * ) account aINNER JOIN district a.district_id= d.district_idWHERE d.A2 = \u2018 Pisek \u2019 Added Indexes : ( time-saving percentage : 87.27 % ) CREATE INDEXaccount_district_id_indexON account ( district_id ) ; CREATE UNIQUE INDEX",
    "district a.district_id= d.district_idWHERE d.A2 = \u2018 Pisek \u2019 Added Indexes : ( time-saving percentage : 87.27 % ) CREATE INDEXaccount_district_id_indexON account ( district_id ) ; CREATE UNIQUE INDEX district_district_id_uindexON district ( district_id ) ; Take Away : Addingindexesinto database significantlyincrease speed SQL queries creates data structure enables database engine quickly locate rows match specific criteria instead scanning entire table.Figure 10 : Two possible solutions explanations improve efficiency presented . first batch examples shows optimize SQL efficiency rewriting SQL based rules . last example show adding indexes databases also improve SQL efficiency without rewriting . B.8 VES Details Regarding E , experiment , consider time main metric represent efficiency , E\u2208 ( \u03f5,30s ) . , \u03f5is small positive constant prevent floating-point overflow . single Eis stable due machine status . Lower Erefers faster execution speed , efficient . Concerning R , represents",
    ", E\u2208 ( \u03f5,30s ) . , \u03f5is small positive constant prevent floating-point overflow . single Eis stable due machine status . Lower Erefers faster execution speed , efficient . Concerning R , represents normalized efficiency ratio human-annotated SQL queries predicted SQL queries reduce influence machine status . stability metric ensured running computation 100 times example , filtering outliers , subsequently 25Wrong Schema Linking ( 41.6 % ) Question : List names schools 30 differencesin enrollmentsbetween K-12 ages 5-17.Please also give full street addressof schools.Evidence : Difference enrollment= ` Enrollment ( K-12 ) ` - ` Enrollment ( Ages 5-17 ) ` Ground Truth : SELECT T1.School , T1.StreetAbrFROM schools T1 INNER JOIN frpm T2 T1.CDSCode = T2.CDSCode T2. ` Enrollment ( K-12 ) ` -T2. ` Enrollment ( Ages 5-17 ) ` > 30 ChatGPT SQL : SELECT s.School , s.Street , s.City , s.Zip schools JOIN frpm f s.CDSCode= f.CDSCode f. ` Enrollment ( K-12 ) ` -f. ` Enrollment ( Ages 5-17 ) ` > 30",
    "` Enrollment ( Ages 5-17 ) ` > 30 ChatGPT SQL : SELECT s.School , s.Street , s.City , s.Zip schools JOIN frpm f s.CDSCode= f.CDSCode f. ` Enrollment ( K-12 ) ` -f. ` Enrollment ( Ages 5-17 ) ` > 30 Question : List accounts earliest trading date 1995.Evidence : FalseGround Truth : SELECT account_idFROM transWHERE STRFTIME ( ' % ' , date ) = '1995 ' ORDER date ASC LIMIT 1ChatGPT SQL : SELECT account_id account date = ( SELECT MIN ( date ) account date LIKE '1995 % ' ) Question : average math score school lowest average score subjects , county located ? Evidence : Average score subjects computed AvgScrMath+ AvgScrRead+ AvgScrWriteGround Truth : SELECT T1.AvgScrMath , T2.County satscoresAS T1 INNER JOIN schools T2 T1.cds = T2.CDSCode T1.AvgScrMath NULLORDER T1.AvgScrMath + T1.AvgScrRead + T1.AvgScrWrite ASC LIMIT 1ChatGPT SQL : SELECT cname , AvgScrMathFROM satscoresJOIN schools satscores.cds= schools.CDSCodeWHERE satscores.rtype= \u2018 \u2019 ORDER ( AvgScrMath+ AvgScrRead+ AvgScrWrite ) ASC",
    "T1.AvgScrWrite ASC LIMIT 1ChatGPT SQL : SELECT cname , AvgScrMathFROM satscoresJOIN schools satscores.cds= schools.CDSCodeWHERE satscores.rtype= \u2018 \u2019 ORDER ( AvgScrMath+ AvgScrRead+ AvgScrWrite ) ASC LIMIT 1Misunderstanding Database Content ( 40.8 % ) Question : average lap time milliseconds lap records set various circuits Italy ? Evidence : average = VG ( milliseconds ) Ground Truth : SELECT CAST ( SUM ( T1.milliseconds ) REAL ) / COUNT ( T1.lap ) lapTimesAS T1 INNER JOIN races T2 T1.raceId = T2.raceId INNER JOIN circuits T3 T2.circuitId = T3.circuitId T3.country = 'Italy \u2019 ChatGPT SQL : SELECT AVG ( milliseconds ) lap_recordsWHERE circuit ( 'Monza ' , 'Imola ' , 'Mugello ' , 'Misano ' ) Question : average , much Student_Clubspend food typical event past ? Evidence : DIVIDE ( SUM ( spent ) , COUNT ( spent ) ) category = 'Food ' ; 'event past ' means event_status= 'Closed \u2019 Ground Truth : SELECT SUM ( spent ) / COUNT ( spent ) budget category = 'Food ' event_status= 'Closed \u2019 ChatGPT",
    ") , COUNT ( spent ) ) category = 'Food ' ; 'event past ' means event_status= 'Closed \u2019 Ground Truth : SELECT SUM ( spent ) / COUNT ( spent ) budget category = 'Food ' event_status= 'Closed \u2019 ChatGPT SQL : SELECT DIVIDE ( SUM ( spent ) , COUNT ( spent ) ) budget category = 'Food ' event_status= 'Closed'Misunderstanding Knowledge Evidence ( 17.6 % ) Question : Name elementary schools Riverside average average math scorefor SAT grater 400 , funding type schools ? Evidence : Average average math = sum ( average math scores ) / count ( schools ) Ground Truth : SELECT T1.sname , T2. ` Charter Funding Type ` satscoresAS T1 INNER JOIN frpmHAVING CAST ( SUM ( T1.AvgScrMath ) REAL ) / COUNT ( T1.cds ) > 400ChatGPT SQL : SELECT s.School , s.FundingType schools sc.rtype= \u2018 E \u2019 sc.AvgScrMath > 400 GROUP s.School , s.FundingTypeQuestion : many meeting events held 2020 ? Syntax Error ( 3.0 % ) Question : much customer 7 consuming April 2013 customer 5 ? Evidence : April 2013 refers \u2018 201304 \u2019",
    "GROUP s.School , s.FundingTypeQuestion : many meeting events held 2020 ? Syntax Error ( 3.0 % ) Question : much customer 7 consuming April 2013 customer 5 ? Evidence : April 2013 refers \u2018 201304 \u2019 yearmonth.dateGround Truth : SELECT SUM ( IIF ( CustomerID= 7 , Consumption , 0 ) ) -SUM ( IIF ( CustomerID= 5 , Consumption , 0 ) ) yearmonthWHERE Date = '201304 \u2019 ChatGPT SQL : SELECT7 , ( SELECT Consumption yearmonthWHERE CustomerID= 7 Date = 201304 ) - ( SELECT Consumption yearmonthWHERE CustomerID= 5 Date = 201304 ) Evidence : meeting events refers type = 'Meeting ' ; held 2020 refers YEAR ( event_date ) = 2020Ground Truth : SELECT COUNT ( event_id ) event type = 'Meeting ' STRFTIME ( ' % ' , COLUMN ) = \u2018 2020 \u2019 ChatGPT SQL : SELECT COUNT ( * ) event type = 'Meeting ' YEAR ( event_date ) = 2020\u2026\u2026Figure 11 : 4 major types error cases presented . cases shortcuts better presentation . computing average . Considering rapid advancement technology , impractical anticipate fastest SQL",
    ") = 2020\u2026\u2026Figure 11 : 4 major types error cases presented . cases shortcuts better presentation . computing average . Considering rapid advancement technology , impractical anticipate fastest SQL performance . Currently , range efficiency ratio , R , defined R\u2208 ( 0 , +\u221e ) .E ( \u02c6Yn ) ( efficiency predicted SQL ) much lower E ( \u02c6Y ) ( efficiency ground truth SQL according EX ) , relative efficiency score Rwill increased . short , higher R refers higher efficiency . measuring VES , run 100 times SQL CPU evaluate average results dropping outliers . STD VES dev set test set 10 trials 0.043 0.025 respectively . detect outliers following procedures : 1 . Compute mean standard deviation dataset . 2.Then calculate lower threshold mean\u22123\u00d7standard_deviation upper threshold mean + 3\u00d7standard_deviation . 3.Statistically , approximately 99.7 % data points fall within 3 standard deviations mean . B.9 Human Performance Collection procedure collecting human performance still rigorous . annotation ,",
    ". 3.Statistically , approximately 99.7 % data points fall within 3 standard deviations mean . B.9 Human Performance Collection procedure collecting human performance still rigorous . annotation , data divided 10 batches better management error tracks experts . first 8 batches data final training data dev data public use , remaining 2 batches data used testing . consider annotation first 8 batches data learning process SQL annotators since erroneous SQLs could fixed experts learn generate good-quality SQLs task . first scores examination , conducted testing set final two batches viewed human performance since \u2019 interrupt assist examination errors preserved . testing , proceed following double-blind SQL annotation procedures Section 3.4 correct SQLs data discussion experts . SQLs second round double-blind annotation collected ground truth . B.10 Distribution Open-source Databases databases B IRDare accordance one following licenses : 26Public Domain Public Domain Mark public domain",
    "round double-blind annotation collected ground truth . B.10 Distribution Open-source Databases databases B IRDare accordance one following licenses : 26Public Domain Public Domain Mark public domain license refers legal designation allows intellectual property , creative works inventions , freely used , shared , built upon anyone without restrictions . work public domain , longer protected copyright , patent , trademark laws . CC-BY Creative Commons Attribution 4.0 International license one open Creative Commons licenses allows users share adapt dataset long give credit creator . CC-BY-SA Creative Commons Attribution-ShareAlike 4.0 International license one open Creative Commons licenses allows users share adapt dataset long give credit creator distribute additions , transformations , changes dataset license . GPL General Public License GPL created Free Software Foundation ( FSF ) also known GNU GPL , used GNU Project . allows users use , study , share , modify software certain terms",
    "dataset license . GPL General Public License GPL created Free Software Foundation ( FSF ) also known GNU GPL , used GNU Project . allows users use , study , share , modify software certain terms conditions . CPOL Code Project Open License software license often used articles , tutorials , sample code shared Code Project website . CPOL intended permissive license , allowing developers use , modify , distribute software without many restrictions imposed licenses like GPL . CC0 Creative Commons Zero public domain dedication tool created Creative Commons . allows creators waive copyright related rights work , effectively placing public domain . means anyone freely use , share , modify , build upon work without seeking permission providing attribution original creator . B.11 SQL Function Taxonomy SQL functions BIRD mentioned Table 1 span across multiple categories including : \u2022 Window Functions , i.e. , ( ) \u2022 Date Functions , i.e. , JULIANDAY ( ) \u2022 Conversion Functions , i.e. , CAST ( ) \u2022",
    "SQL functions BIRD mentioned Table 1 span across multiple categories including : \u2022 Window Functions , i.e. , ( ) \u2022 Date Functions , i.e. , JULIANDAY ( ) \u2022 Conversion Functions , i.e. , CAST ( ) \u2022 Math Functions , i.e. , ROUND ( ) \u2022 String Functions , i.e. , SUBSTR ( ) B.12 Keyword Statistic conducted comprehensive analysis keywords employed BIRD dataset visualize results form nice-looking word cloud , found Figure 12 . classify keywords 7 following categories : Main Body Keywords \u2022SELECT \u2022FROM \u2022WHERE \u2022AND \u2022OR\u2022NOT \u2022IN\u2022EXISTS \u2022IS\u2022 NULL \u2022IIF \u2022CASE \u2022CASE . Join Keywords \u2022INNER JOIN \u2022LEFT JOIN \u2022ON\u2022AS . Clause Keywords \u2022BETWEEN \u2022LIKE \u2022LIMIT \u2022ORDER \u2022ASC \u2022DESC \u2022GROUP \u2022 \u2022UNION \u2022ALL \u2022EXCEPT \u2022PARTITION . 27Figure 12 : Keyword cloud presentation SQLs BIRD . Aggregation Keywords \u2022AVG \u2022COUNT \u2022MAX \u2022MIN \u2022ROUND \u2022SUM . Scalar Keywords \u2022ABS \u2022LENGTH \u2022STRFTIME \u2022JULIADAY \u2022NOW \u2022CAST \u2022SUBSTR \u2022INSTR . Comparison Keywords \u2022=\u2022 > \u2022 < \u2022 > =\u2022 < =\u2022 ! = . Computing Keywords \u2022-\u2022+\u2022 * \u2022/ . B.13 Study Text-to-SQL Models",
    "\u2022SUM . Scalar Keywords \u2022ABS \u2022LENGTH \u2022STRFTIME \u2022JULIADAY \u2022NOW \u2022CAST \u2022SUBSTR \u2022INSTR . Comparison Keywords \u2022=\u2022 > \u2022 < \u2022 > =\u2022 < =\u2022 ! = . Computing Keywords \u2022-\u2022+\u2022 * \u2022/ . B.13 Study Text-to-SQL Models fundamental principle cross-domain text-to-SQL parser involves construction encoder learn representations questions schemas , followed decoder generate SQLs [ 37 ] . example , IRNET [ 12 ] designs encoder consisting attention-based Bi-LSTM learning question schema representations , decoder predict SQLs based encoded intermediate representations . RATSQL [ 43 ] , SDSQL [ 17 ] , LGESQL [ 5 ] , S2SQL [ 18 ] , Proton [ 44 ] enhance representation learning natural language questions database schema via relational graph neural network . R2SQL [ 16 ] , SCORE [ 54 ] , STAR [ 4 ] enhance contextual learning conversational text-to-SQL tasks . Later , sequence-to-sequence pre-trained language models ( PLMs ) T5 [ 38 ] become popular text-to-SQL tasks due portability capability generation across different",
    "conversational text-to-SQL tasks . Later , sequence-to-sequence pre-trained language models ( PLMs ) T5 [ 38 ] become popular text-to-SQL tasks due portability capability generation across different datasets . models achieve impressive results fine- tuning minimal effort . Furthermore , RASAT [ 36 ] enhances T5 \u2019 structural information encoding via schema alignment encoder , Graphix [ 27 ] equips T5 multi-hop reasoning achieve state-of-the-art results complicated cross-domain text-to-SQL tasks . recent years , LLMs ChatGPT [ 33 ] , Palm [ 8 ] , OPT [ 56 ] , attracted considerable attention due powerful zero-shot reasoning domain generalization capabilities . ChatGPT perform exceptionally well semantic parsing tasks , including text-to-SQL tasks , minimal input data . fact , BIRD project , ChatGPT even performs impressively initially expected . Study SQL Efficiency Efficient execution SQL queries big databases significant topic academia industries . Many techniques proposed improve SQL",
    "ChatGPT even performs impressively initially expected . Study SQL Efficiency Efficient execution SQL queries big databases significant topic academia industries . Many techniques proposed improve SQL query efficiency , index selection [ 22 ] , SQL optimization [ 26,61 ] , etc . SQL optimization common method enhancing efficiency SQL queries . Several SQL optimization algorithms [ 28,30,47 ] , rule-based optimization cost-based optimization , proven effective . Rule-based optimization employs set principles transform SQL query form executed efficiently . hand , cost-based optimization estimates execution cost various query plans selects one lowest cost analyzing statistic distribution database values . Similar NLP community , also recent works utilizing artificial intelligence query optimization [ 61 ] . Index prediction another important technique improving SQL execution efficiency . Researchers propose many algorithms index prediction [ 60 ] based various optimization criteria ,",
    "[ 61 ] . Index prediction another important technique improving SQL execution efficiency . Researchers propose many algorithms index prediction [ 60 ] based various optimization criteria , minimizing SQL execution time , maximizing index utilization . work , provide VES measure efficiency text-to-SQL generators encourage generate accurate fast SQLs users . 28"
]